# Handover ‚Äì An√°lise e Engenharia de Dados | Barra Mansa Alimentos

**Autor:** Jo√£o Lima<br> 
**Departamento:** Controladoria Financeira<br>
**Data:** Janeiro 2026<br>

---

## 1. Linguagens de Programa√ß√£o

### 1.1. SQL
- [1.1.1. SQL B√°sico (SELECT, WHERE, FROM)](#111-sql-b√°sico-select-where-from)
- [1.1.2. SQL Intermedi√°rio (JOINs, Agrega√ß√µes, CTEs, Window Functions, UNION)](#112-sql-intermedi√°rio-joins-agrega√ß√µes-ctes-window-functions-union)
- [1.1.3. SQL Aplicado - COFINS a Recuperar (exemplo real)](#113-sql-aplicado-cofins-a-recuperar-exemplo-real)

### 1.2. Python
- [1.2.1. Sintaxe B√°sica (tipos, cole√ß√µes, operadores, controle)](#121-sintaxe-basica-tipos-colecoes-operadores-controle)
- [1.2.2. Recursos da Linguagem (comprehension, decorators, context manager)](#122-recursos-da-linguagem-comprehension-decorators-context-manager)
- [1.2.3. Pandas para An√°lise Explorat√≥ria](#123-pandas-para-analise-exploratoria)

---

## 2. Conceitos e Ciclo de Vida

### 2.1. Ciclo de Vida da An√°lise de Dados
- [2.1.1. Etapas do Ciclo (6 etapas)](#211-etapas-do-ciclo-6-etapas)
- [2.1.2. Detalhamento das Etapas](#212-detalhamento-das-etapas)

### 2.2. Arquitetura ELT
- [2.2.1. Vis√£o Geral do Processo](#221-visao-geral-do-processo)
- [2.2.2. Componentes Principais (fontes, EL, transforma√ß√£o, camadas, visualiza√ß√£o)](#222-componentes-principais-fontes-el-transformacao-camadas-visualizacao)

---

## 3. Ambiente e Ferramentas

### 3.1. WSL/Linux
- [3.1.1. Navega√ß√£o](#311-navegacao)
- [3.1.2. Gerenciamento de Arquivos](#312-gerenciamento-de-arquivos)
- [3.1.3. Gerenciamento de Pacotes](#313-gerenciamento-de-pacotes)

### 3.2. Python (Ambiente)
- [3.2.1. Criar e Ativar Ambiente Virtual](#321-criar-e-ativar-ambiente-virtual)
- [3.2.2. Gerenciar Depend√™ncias](#322-gerenciar-dependencias)

### 3.3. VS Code
- [3.3.1. Extens√µes Recomendadas](#331-extensoes-recomendadas)
- [3.3.2. Atalhos Principais](#332-atalhos-principais)

### 3.4. Git
- [3.4.1. Comandos B√°sicos](#341-comandos-basicos)
- [3.4.2. Desfazer Altera√ß√µes](#342-desfazer-alteracoes)
- [3.4.3. Resolu√ß√£o de Conflitos](#343-resolucao-de-conflitos)
- [3.4.4. Boas Pr√°ticas](#344-boas-praticas)

### 3.5. Fluxo de Desenvolvimento
- [3.5.1. Git ‚Üí dbt ‚Üí GitHub (passo a passo)](#351-git-dbt-github-passo-a-passo)

---

## 4. Stack de Dados

### 4.1. AWS
- [4.1.1. Vis√£o Geral](#411-visao-geral)
- [4.1.2. S3 (staging)](#412-s3-staging)
- [4.1.3. EC2 (Airflow)](#413-ec2-airflow)
- [4.1.4. Redshift (DW)](#414-redshift-dw)

### 4.2. dbt
- [4.2.1. Estrutura do Projeto](#421-estrutura-do-projeto)
- [4.2.2. Camadas de Dados](#422-camadas-de-dados)
- [4.2.3. Materializa√ß√µes](#423-materializacoes)
- [4.2.4. Sources e Refs](#424-sources-e-refs)
- [4.2.5. Testes](#425-testes)
- [4.2.6. Jinja B√°sico](#426-jinja-basico)
- [4.2.7. Comandos dbt](#427-comandos-dbt)

### 4.3. Airflow
- [4.3.1. Conceitos Essenciais](#431-conceitos-essenciais)
- [4.3.2. Operadores](#432-operadores)
- [4.3.3. Anatomia de uma DAG](#433-anatomia-de-uma-dag)
- [4.3.4. Hooks e Conex√µes](#434-hooks-e-conexoes)
- [4.3.5. Recursos Intermedi√°rios](#435-recursos-intermediarios)
- [4.3.6. Airflow na Barra Mansa](#436-airflow-na-barra-mansa)
- [4.3.7. Como Adicionar Nova Tabela](#437-como-adicionar-nova-tabela)
- [4.3.8. Opera√ß√£o](#438-operacao)

### 4.4. Power BI
- [4.4.1. Conex√£o com Fontes](#441-conexao-com-fontes)
- [4.4.2. Modelagem de Dados](#442-modelagem-de-dados)
- [4.4.3. DAX Intermedi√°rio](#443-dax-intermediario)
- [4.4.4. Design de Layouts](#444-design-de-layouts)
- [4.4.5. Cria√ß√£o de Visuais](#445-criacao-de-visuais)
- [4.4.6. Interatividade](#446-interatividade)
- [4.4.7. Boas Pr√°ticas](#447-boas-praticas)
- [4.4.8. Exemplos Contextualizados](#448-exemplos-contextualizados)

---

## 5. Qualidade e Valida√ß√£o

### 5.1. Valida√ß√£o Cruzada
- [5.1.1. Import√¢ncia](#511-importancia)
- [5.1.2. Princ√≠pios](#512-principios)
- [5.1.3. Recomenda√ß√£o](#513-recomendacao)

---

## 6. Pr√°tica

### 6.1. Exerc√≠cios SQL Anal√≠ticos
- [6.1.1. B√°sico (SELECT + WHERE)](#611-basico-select-where)
- [6.1.2. JOINs](#612-joins)
- [6.1.3. Agrega√ß√µes](#613-agregacoes)
- [6.1.4. CTEs](#614-ctes)
- [6.1.5. Window Functions](#615-window-functions)
- [6.1.6. UNION + Subconsultas + DML](#616-union-subconsultas-dml)

### 6.2. Exerc√≠cios Python para An√°lise de Dados
- [6.2.1. Sintaxe B√°sica](#621-sintaxe-basica)
- [6.2.2. Recursos da Linguagem](#622-recursos-da-linguagem)
- [6.2.3. Pandas para An√°lise Explorat√≥ria](#623-pandas-para-analise-exploratoria)

### 6.3. Exerc√≠cios DAX
- [6.3.1. Medidas B√°sicas com Filtros](#631-medidas-basicas-com-filtros)
- [6.3.2. Compara√ß√µes Temporais](#632-comparacoes-temporais)
- [6.3.3. Totalizadores e Contextos](#633-totalizadores-e-contextos)
- [6.3.4. Indicadores e L√≥gica Condicional](#634-indicadores-e-logica-condicional)
- [6.3.5. L√≥gica Avan√ßada e Itera√ß√£o](#635-logica-avancada-e-iteracao)

### 6.4. Exerc√≠cios Linguagem M (Power Query)
- [6.4.1. Transforma√ß√µes B√°sicas](#641-transformacoes-basicas)
- [6.4.2. Transforma√ß√µes Intermedi√°rias](#642-transformacoes-intermediarias)
- [6.4.3. An√°lise de Pipeline Completo](#643-analise-de-pipeline-completo)

---

# 1. Linguagens de Programa√ß√£o

## 1.1. SQL

Guia visual e pr√°tico para constru√ß√£o de consultas SQL no ambiente Barra Mansa Alimentos.

### 1.1.1. SQL B√°sico (SELECT, WHERE, FROM)

#### Estrutura de uma Consulta SQL

O processo completo de constru√ß√£o de uma query SQL segue tr√™s passos sequenciais:


- Liste as colunas que deseja exibir
- Use o alias da tabela (N.) antes de cada coluna

**Exemplo:**
```sql
SELECT N.codemp, N.codfil, N.numnfi, N.datent
```

### 2¬∫ Passo: FROM - DE ONDE v√™m os dados

- Especifique a tabela e crie um alias para facilitar refer√™ncias

**Exemplo:**
```sql
FROM e660nfc N
-- e660nfc = tabela | N = alias/apelido
```

### 3¬∫ Passo: WHERE - QUAIS dados filtrar

- Defina condi√ß√µes para limitar os resultados
- Use AND/OR para combinar m√∫ltiplas condi√ß√µes

**Exemplo:**
```sql
WHERE N.codemp = 1 
  AND N.datent >= '20250615' 
  AND N.vlrtot > 1000
```

### Consulta Completa de Exemplo

```sql
SELECT N.codemp, N.codfil, N.numnfi, N.datent
FROM e660nfc N
WHERE N.codemp = 1 
  AND N.datent >= '20250615' 
  AND N.vlrtot > 1000
```

**Ambiente de execu√ß√£o:** SSMS (SQL Server Management Studio) no Banco de Dados `sapiens_prod`

---

### 1.1.2. SQL Intermedi√°rio (JOINs, Agrega√ß√µes, CTEs, Window Functions, UNION)

---

#### JOINs - Combinando Dados de M√∫ltiplas Tabelas

##### LEFT JOIN
Retorna todos os registros da tabela principal (esquerda) e os correspondentes da tabela secund√°ria. Se n√£o houver correspond√™ncia, retorna NULL.

**Exemplo do contexto:**
```sql
FROM E640LCT L
LEFT JOIN e045pla P
    ON P.codemp = L.codemp
   AND P.ctared = L.ctadeb
```
- Busca **todos** os lan√ßamentos da E640LCT
- Traz descri√ß√µes do plano de contas quando houver correspond√™ncia
- Se n√£o houver conta correspondente, P.descta ser√° NULL

##### INNER JOIN
Retorna apenas registros que t√™m correspond√™ncia em ambas as tabelas.
```sql
FROM E640LCT L
INNER JOIN e045pla P
    ON P.codemp = L.codemp
   AND P.ctared = L.ctadeb
```
- Retornaria apenas lan√ßamentos que t√™m conta no plano de contas

##### RIGHT JOIN
Retorna todos os registros da tabela secund√°ria (direita) e os correspondentes da tabela principal.
```sql
FROM E640LCT L
RIGHT JOIN e045pla P
    ON P.codemp = L.codemp
   AND P.ctared = L.ctadeb
```

##### FULL OUTER JOIN
Retorna todos os registros quando h√° correspond√™ncia em qualquer uma das tabelas.
```sql
FROM E640LCT L
FULL OUTER JOIN e045pla P
    ON P.codemp = L.codemp
   AND P.ctared = L.ctadeb
```

---

#### UNION - Combinando Resultados de M√∫ltiplas Consultas

Combina os resultados de duas ou mais queries em um √∫nico conjunto de dados.

##### UNION vs UNION ALL

**UNION** - Remove duplicatas automaticamente:
```sql
SELECT ctadeb, vlrlct FROM E640LCT WHERE ctadeb = '10530'
UNION
SELECT ctacre, vlrlct FROM E640LCT WHERE ctacre = '10530'
```

**UNION ALL** - Mant√©m todas as linhas, incluindo duplicatas (mais r√°pido):
```sql
SELECT ctadeb, vlrlct FROM E640LCT WHERE ctadeb = '10530'
UNION ALL
SELECT ctacre, vlrlct FROM E640LCT WHERE ctacre = '10530'
```

##### Exemplo Pr√°tico - COFINS a Recuperar
```sql
-- Lan√ßamentos a CR√âDITO (conta 10.530 recebendo)
SELECT
    L.codemp,
    L.codfil,
    L.numlct,
    CAST(L.datlct AS DATE) AS datlct,
    (L.vlrlct * -1) AS vlrlct,  -- Inverte o sinal
    'CR√âDITO' AS tipo_lancamento
FROM E640LCT L
WHERE L.ctacre = '10530'
  AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
  AND L.sitlct = 2

UNION

-- Lan√ßamentos a D√âBITO (conta 10.530 pagando)
SELECT
    L.codemp,
    L.codfil,
    L.numlct,
    CAST(L.datlct AS DATE) AS datlct,
    L.vlrlct,  -- Mant√©m o sinal positivo
    'D√âBITO' AS tipo_lancamento
FROM E640LCT L
WHERE L.ctadeb = '10530'
  AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
  AND L.sitlct = 2
```

**Por que usar UNION?**
- Conta cont√°bil pode aparecer tanto no d√©bito quanto no cr√©dito
- UNION consolida ambas as movimenta√ß√µes em uma √∫nica vis√£o
- Permite padronizar valores (invertendo sinal quando necess√°rio)

**Regras do UNION:**
- Todas as queries devem ter o **mesmo n√∫mero de colunas**
- Colunas correspondentes devem ter **tipos de dados compat√≠veis**
- Nomes das colunas v√™m da **primeira query**

---

#### Agrega√ß√µes - Sumarizando Dados

Fun√ß√µes que calculam valores sobre grupos de registros.

##### Fun√ß√µes de Agrega√ß√£o Principais
```sql
-- Soma total de COFINS por filial
SELECT 
    L.codfil,
    SUM(L.vlrlct) AS total_cofins,
    COUNT(*) AS qtd_lancamentos,
    COUNT(DISTINCT L.numlct) AS qtd_lancamentos_unicos,
    AVG(L.vlrlct) AS media_valor,
    MAX(L.vlrlct) AS maior_valor,
    MIN(L.vlrlct) AS menor_valor
FROM E640LCT L
WHERE L.ctacre = '10530'
  AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
GROUP BY L.codfil
```

**Fun√ß√µes dispon√≠veis:**
- `SUM()` - Soma valores
- `COUNT()` - Conta registros
- `COUNT(DISTINCT)` - Conta valores √∫nicos
- `AVG()` - Calcula m√©dia
- `MAX()` / `MIN()` - Valores m√°ximo/m√≠nimo

##### HAVING - Filtro Ap√≥s Agrega√ß√£o
```sql
SELECT 
    L.codfil,
    SUM(L.vlrlct) AS total_cofins,
    COUNT(*) AS qtd_lancamentos
FROM E640LCT L
WHERE L.ctacre = '10530'
GROUP BY L.codfil
HAVING SUM(L.vlrlct) > 10000  -- Filtra ap√≥s agrega√ß√£o
```

**Diferen√ßa entre WHERE e HAVING:**
- `WHERE` - Filtra **antes** da agrega√ß√£o (registros individuais)
- `HAVING` - Filtra **depois** da agrega√ß√£o (grupos)

---

#### CTEs (Common Table Expressions) - Consultas Tempor√°rias

Cria "tabelas tempor√°rias" nomeadas para organizar queries complexas de forma leg√≠vel.

##### Sintaxe B√°sica
```sql
WITH nome_cte AS (
    SELECT coluna1, coluna2
    FROM tabela
    WHERE condicao
)
SELECT * FROM nome_cte
```

##### Exemplo Pr√°tico - An√°lise de COFINS
```sql
WITH cofins_debito AS (
    -- Totaliza lan√ßamentos a d√©bito
    SELECT 
        codemp, 
        codfil, 
        SUM(vlrlct) AS total_debito,
        COUNT(*) AS qtd_debito
    FROM E640LCT
    WHERE ctadeb = '10530'
      AND datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
      AND sitlct = 2
    GROUP BY codemp, codfil
),
cofins_credito AS (
    -- Totaliza lan√ßamentos a cr√©dito
    SELECT 
        codemp, 
        codfil, 
        SUM(vlrlct) AS total_credito,
        COUNT(*) AS qtd_credito
    FROM E640LCT
    WHERE ctacre = '10530'
      AND datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
      AND sitlct = 2
    GROUP BY codemp, codfil
)
-- Consolida d√©bito e cr√©dito
SELECT 
    COALESCE(D.codfil, C.codfil) AS codfil,
    COALESCE(D.total_debito, 0) AS total_debito,
    COALESCE(C.total_credito, 0) AS total_credito,
    (COALESCE(D.total_debito, 0) - COALESCE(C.total_credito, 0)) AS saldo_liquido,
    COALESCE(D.qtd_debito, 0) AS lancamentos_debito,
    COALESCE(C.qtd_credito, 0) AS lancamentos_credito
FROM cofins_debito D
FULL OUTER JOIN cofins_credito C
    ON D.codemp = C.codemp
   AND D.codfil = C.codfil
```

**Vantagens das CTEs:**
- C√≥digo mais leg√≠vel e organizado
- Reutiliza√ß√£o de resultados intermedi√°rios
- Substitui√ß√£o elegante de subqueries complexas
- Facilita debugging (pode testar cada CTE separadamente)
- **Alternativa ao UNION** quando voc√™ quer manter os dados separados para an√°lise

##### CTEs Recursivas
```sql
WITH hierarquia_contas AS (
    -- √Çncora: contas de n√≠vel superior
    SELECT ctared, descta, ctasup, 1 AS nivel
    FROM e045pla
    WHERE ctasup IS NULL
    
    UNION ALL
    
    -- Recurs√£o: contas subordinadas
    SELECT p.ctared, p.descta, p.ctasup, h.nivel + 1
    FROM e045pla p
    INNER JOIN hierarquia_contas h
        ON p.ctasup = h.ctared
)
SELECT * FROM hierarquia_contas
ORDER BY nivel, ctared
```

---

#### Window Functions - C√°lculos Anal√≠ticos

Realizam c√°lculos mantendo o detalhamento de cada linha (diferente do GROUP BY que agrupa).

##### Sintaxe B√°sica
```sql
funcao_janela() OVER (
    [PARTITION BY coluna]
    [ORDER BY coluna]
    [ROWS/RANGE BETWEEN ... AND ...]
)
```

##### Fun√ß√µes de Ranking
```sql
SELECT 
    L.numlct,
    L.datlct,
    L.codfil,
    L.vlrlct,
    -- Numera√ß√£o sequencial √∫nica
    ROW_NUMBER() OVER (ORDER BY L.vlrlct DESC) AS ranking_geral,
    -- Ranking com empates (pula n√∫meros)
    RANK() OVER (ORDER BY L.vlrlct DESC) AS rank_com_pulo,
    -- Ranking com empates (sem pular n√∫meros)
    DENSE_RANK() OVER (ORDER BY L.vlrlct DESC) AS rank_denso,
    -- Ranking por filial
    ROW_NUMBER() OVER (PARTITION BY L.codfil ORDER BY L.vlrlct DESC) AS ranking_filial
FROM E640LCT L
WHERE L.ctacre = '10530'
  AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
```

##### Fun√ß√µes de Agrega√ß√£o com OVER
```sql
SELECT 
    L.numlct,
    L.datlct,
    L.codfil,
    L.vlrlct,
    -- Soma acumulada ordenada por data
    SUM(L.vlrlct) OVER (ORDER BY L.datlct) AS soma_acumulada_geral,
    -- Soma acumulada por filial
    SUM(L.vlrlct) OVER (PARTITION BY L.codfil ORDER BY L.datlct) AS soma_acumulada_filial,
    -- M√©dia m√≥vel dos √∫ltimos 3 lan√ßamentos
    AVG(L.vlrlct) OVER (ORDER BY L.datlct ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS media_movel_3,
    -- Total geral (sem parti√ß√£o)
    SUM(L.vlrlct) OVER () AS total_geral,
    -- Percentual do total
    (L.vlrlct * 100.0 / SUM(L.vlrlct) OVER ()) AS percentual_total
FROM E640LCT L
WHERE L.ctacre = '10530'
  AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
```

##### Fun√ß√µes de Acesso a Linhas
```sql
SELECT 
    L.numlct,
    L.datlct,
    L.vlrlct,
    -- Valor do lan√ßamento anterior
    LAG(L.vlrlct, 1) OVER (ORDER BY L.datlct) AS valor_anterior,
    -- Valor do pr√≥ximo lan√ßamento
    LEAD(L.vlrlct, 1) OVER (ORDER BY L.datlct) AS valor_proximo,
    -- Diferen√ßa em rela√ß√£o ao anterior
    L.vlrlct - LAG(L.vlrlct, 1) OVER (ORDER BY L.datlct) AS variacao,
    -- Primeiro valor do per√≠odo
    FIRST_VALUE(L.vlrlct) OVER (ORDER BY L.datlct) AS primeiro_valor,
    -- √öltimo valor do per√≠odo
    LAST_VALUE(L.vlrlct) OVER (ORDER BY L.datlct ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS ultimo_valor
FROM E640LCT L
WHERE L.ctacre = '10530'
  AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
```

##### Cl√°usulas de Window Frame
```sql
SELECT 
    L.datlct,
    L.vlrlct,
    -- Soma dos √∫ltimos 7 dias (incluindo hoje)
    SUM(L.vlrlct) OVER (
        ORDER BY L.datlct 
        RANGE BETWEEN INTERVAL '7' DAY PRECEDING AND CURRENT ROW
    ) AS soma_7_dias,
    -- M√©dia das 5 linhas anteriores at√© a atual
    AVG(L.vlrlct) OVER (
        ORDER BY L.datlct 
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    ) AS media_movel_5,
    -- Total da parti√ß√£o inteira
    SUM(L.vlrlct) OVER (
        PARTITION BY L.codfil
        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
    ) AS total_filial
FROM E640LCT L
WHERE L.ctacre = '10530'
```

**Diferen√ßa entre ROWS e RANGE:**
- `ROWS` - Define janela por **n√∫mero de linhas** f√≠sicas
- `RANGE` - Define janela por **valores** (√∫til para datas)

---

#### Aplica√ß√£o Pr√°tica no Contexto

A query de COFINS a Recuperar demonstra a aplica√ß√£o desses conceitos:

1. **LEFT JOIN** - Enriquece dados com descri√ß√µes do plano de contas
2. **UNION** - Consolida lan√ßamentos de d√©bito e cr√©dito em vis√£o √∫nica
3. **Agrega√ß√£o** - Poderia totalizar movimenta√ß√µes por per√≠odo/filial
4. **CTEs** - Alternativa para separar l√≥gica de d√©bito/cr√©dito antes de consolidar
5. **Window Functions** - An√°lise de evolu√ß√£o temporal e c√°lculo de saldos acumulados

##### Exemplo Completo Combinando T√©cnicas
```sql
WITH lancamentos_consolidados AS (
    -- CTE: Consolida d√©bito e cr√©dito com UNION
    SELECT
        L.codemp,
        L.codfil,
        L.numlct,
        CAST(L.datlct AS DATE) AS datlct,
        (L.vlrlct * -1) AS vlrlct,
        'CR√âDITO' AS tipo,
        L.cpllct
    FROM E640LCT L
    WHERE L.ctacre = '10530'
      AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
      AND L.sitlct = 2
    
    UNION ALL
    
    SELECT
        L.codemp,
        L.codfil,
        L.numlct,
        CAST(L.datlct AS DATE) AS datlct,
        L.vlrlct,
        'D√âBITO' AS tipo,
        L.cpllct
    FROM E640LCT L
    WHERE L.ctadeb = '10530'
      AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
      AND L.sitlct = 2
)
-- Query principal com JOINs, Agrega√ß√µes e Window Functions
SELECT 
    LC.codfil,
    LC.datlct,
    LC.tipo,
    COUNT(*) AS qtd_lancamentos,
    SUM(LC.vlrlct) AS total_dia,
    -- Window Function: Saldo acumulado por filial
    SUM(SUM(LC.vlrlct)) OVER (
        PARTITION BY LC.codfil 
        ORDER BY LC.datlct
    ) AS saldo_acumulado,
    -- Window Function: M√©dia m√≥vel 7 dias
    AVG(SUM(LC.vlrlct)) OVER (
        PARTITION BY LC.codfil 
        ORDER BY LC.datlct 
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) AS media_movel_7_dias
FROM lancamentos_consolidados LC
GROUP BY LC.codfil, LC.datlct, LC.tipo
ORDER BY LC.codfil, LC.datlct, LC.tipo
```

---

### 1.1.3. SQL Aplicado - COFINS a Recuperar (exemplo real)

```sql
-- =========================================================
-- Query: COFINS a Recuperar ‚Äì Vis√£o Cont√°bil (Conta 10.530)
-- Descri√ß√£o: Consulta lan√ßamentos cont√°beis da conta 10.530 (COFINS a Recuperar)
--             excluindo lotes espec√≠ficos j√° processados
--             Uni√£o de lan√ßamentos a d√©bito e cr√©dito
-- =========================================================

SELECT
    L.codemp,
    L.codfil,
    L.numlct,
    CAST(L.datlct AS DATE) AS datlct,
    L.ctadeb,
    P.descta AS P_descta,
    L.ctacre,
    A.descta AS A_descta,
    (L.vlrlct * -1) AS vlrlct,
    L.cpllct,
    L.orilct,
    L.numlot,
    L.temaux,
    L.codusu,
    N.numnfi
FROM E640LCT L
LEFT JOIN e045pla P
    ON P.codemp = L.codemp
   AND P.ctared = L.ctadeb
LEFT JOIN e045pla A
    ON A.codemp = L.codemp
   AND A.ctared = L.ctacre
LEFT JOIN E644LNF N
    ON N.codemp = L.codemp
   AND N.numlct = L.numlct
WHERE
    L.ctacre = '10530'
    AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
    AND L.codfil = 4
    AND L.numlot NOT IN ('52660', '52751', '52826')
    AND L.sitlct = 2

UNION

SELECT
    L.codemp,
    L.codfil,
    L.numlct,
    CAST(L.datlct AS DATE) AS datlct,
    L.ctadeb,
    P.descta AS P_descta,
    L.ctacre,
    A.descta AS A_descta,
    L.vlrlct,
    L.cpllct,
    L.orilct,
    L.numlot,
    L.temaux,
    L.codusu,
    N.numnfi
FROM E640LCT L
LEFT JOIN e045pla P
    ON P.codemp = L.codemp
   AND P.ctared = L.ctadeb
LEFT JOIN e045pla A
    ON A.codemp = L.codemp
   AND A.ctared = L.ctacre
LEFT JOIN E644LNF N
    ON N.codemp = L.codemp
   AND N.numlct = L.numlct
WHERE
    L.ctadeb = '10530'
    AND L.datlct BETWEEN DATEADD(DAY, -90, GETDATE()) AND GETDATE()
    AND L.codfil = 4
    AND L.numlot NOT IN ('52660', '52751', '52826')
    AND L.sitlct = 2;

```

**Ambiente de execu√ß√£o:** SSMS (SQL Server Management Studio) no Banco de Dados `sapiens_prod`

---

### Objetivo da Consulta

Extrair todos os lan√ßamentos cont√°beis da conta **10.530** (COFINS a Recuperar) nos √∫ltimos 90 dias da filial 4, excluindo lotes espec√≠ficos j√° processados.

### Estrutura da Query

A consulta √© dividida em duas partes unidas por `UNION`:

#### Parte 1 - Lan√ßamentos a Cr√©dito

- Busca quando a conta 10.530 est√° em `ctacre` (lado cr√©dito)
- Inverte o sinal do valor (`vlrlct * -1`) para padronizar visualiza√ß√£o
- Retorna movimentos de entrada/cr√©dito de COFINS

#### Parte 2 - Lan√ßamentos a D√©bito

- Busca quando a conta 10.530 est√° em `ctadeb` (lado d√©bito)
- Mant√©m o valor positivo original
- Retorna movimentos de sa√≠da/d√©bito de COFINS

### Tabelas Utilizadas

| Tabela | Descri√ß√£o |
|--------|-----------|
| `E640LCT` | Lan√ßamentos cont√°beis (tabela principal) |
| `e045pla` | Plano de contas (descri√ß√£o das contas d√©bito e cr√©dito) |
| `E644LNF` | Vincula√ß√£o com n√∫meros de notas fiscais |

### Filtros Aplicados

| Filtro | Valor |
|--------|-------|
| Per√≠odo | √öltimos 90 dias |
| Filial | 4 |
| Lotes exclu√≠dos | 52660, 52751, 52826 |
| Situa√ß√£o do lan√ßamento | 2 (contabilizado) |

### Resultado Esperado

Vis√£o consolidada dos movimentos de COFINS a Recuperar com valores, descri√ß√µes das contas, complementos hist√≥ricos e v√≠nculos com notas fiscais.

---

## 1.2. Python

Guia r√°pido com a base m√≠nima da linguagem.

### 1.2.1. Sintaxe B√°sica (tipos, cole√ß√µes, operadores, controle) {#121-sintaxe-b√°sica-tipos-cole√ß√µes-operadores-controle}


#### Tipos de Dados

```python
# String (texto)
nome = "Jo√£o"
query = 'SELECT * FROM tabela'

# Inteiro e Float (n√∫meros)
quantidade = 100
preco = 49.90

# Boolean (verdadeiro/falso)
ativo = True
processado = False

# None (aus√™ncia de valor)
resultado = None
```

---

#### Cole√ß√µes

**Quando usar cada uma:**
- **Lista** ‚Üí quando a ordem importa e pode mudar
- **Dicion√°rio** ‚Üí quando precisa buscar por chave
- **Tupla** ‚Üí quando n√£o pode mudar (dados fixos)

#### Lista
Sequ√™ncia ordenada e mut√°vel.
```python
frutas = ["ma√ß√£", "banana", "laranja"]
frutas.append("uva")          # Adiciona
frutas[0]                     # Acessa: "ma√ß√£"
len(frutas)                   # Tamanho: 4
```

#### Dicion√°rio
Pares chave-valor.
```python
pessoa = {
    "nome": "Jo√£o",
    "idade": 30,
    "ativo": True
}
pessoa["nome"]                # Acessa: "Jo√£o"
pessoa["cargo"] = "Analista"  # Adiciona chave
pessoa.keys()                 # Lista chaves
pessoa.values()               # Lista valores
```

#### Tupla
Sequ√™ncia imut√°vel.
```python
coordenadas = (10, 20)
host, porta = ("localhost", 5432)  # Desempacotamento
```

---

### Operadores

```python
# Aritm√©ticos
soma = 10 + 5         # 15
divisao = 10 / 3      # 3.333
inteiro = 10 // 3     # 3
resto = 10 % 3        # 1

# Compara√ß√£o
10 == 10              # True
10 != 5               # True
10 > 5                # True
10 <= 10              # True

# L√≥gicos
True and False        # False
True or False         # True
not True              # False
```

---

### Estruturas de Controle

#### Condicional
```python
idade = 25

if idade >= 18:
    print("Maior de idade")
elif idade >= 12:
    print("Adolescente")
else:
    print("Crian√ßa")
```

#### Loop For
```python
# Iterando lista
frutas = ["ma√ß√£", "banana", "laranja"]
for fruta in frutas:
    print(fruta)

# Iterando com √≠ndice
for i, fruta in enumerate(frutas):
    print(f"{i}: {fruta}")

# Range
for i in range(5):       # 0, 1, 2, 3, 4
    print(i)
```

#### Loop While
```python
contador = 0
while contador < 3:
    print(contador)
    contador += 1
```

#### Controle de Loop
```python
for i in range(10):
    if i == 3:
        continue      # Pula para pr√≥xima itera√ß√£o
    if i == 7:
        break         # Sai do loop completamente
    print(i)          # Imprime: 0, 1, 2, 4, 5, 6
```

---

### Fun√ß√µes

#### Definir e Chamar
```python
def saudacao(nome):
    return f"Ol√°, {nome}!"

mensagem = saudacao("Jo√£o")   # "Ol√°, Jo√£o!"
```

#### Par√¢metros com Valor Padr√£o
```python
def conectar(host, porta=5432):
    return f"{host}:{porta}"

conectar("localhost")         # "localhost:5432"
conectar("localhost", 3306)   # "localhost:3306"
```

#### M√∫ltiplos Retornos
```python
def dividir(a, b):
    quociente = a // b
    resto = a % b
    return quociente, resto

q, r = dividir(10, 3)         # q=3, r=1
```

---

#### Tratamento de Erros

**Quando usar:** Evita que o script pare por erros previs√≠veis (conex√£o, arquivo n√£o encontrado, divis√£o por zero).

```python
try:
    resultado = 10 / 0
except ZeroDivisionError:
    print("Erro: divis√£o por zero")
except Exception as e:
    print(f"Erro: {e}")
finally:
    print("Sempre executa")  # Limpeza, fechar conex√µes
```

---

#### Manipula√ß√£o de Strings

```python
texto = "  Ol√° Mundo  "

texto.strip()                 # "Ol√° Mundo"
texto.lower()                 # "  ol√° mundo  "
texto.upper()                 # "  OL√Å MUNDO  "
texto.replace("Mundo", "Python")

# f-strings (formata√ß√£o)
nome = "Jo√£o"
idade = 30
f"Nome: {nome}, Idade: {idade}"

# Split e Join
"a,b,c".split(",")            # ["a", "b", "c"]
",".join(["a", "b", "c"])     # "a,b,c"
```

---

#### Bibliotecas Essenciais

##### Importa√ß√£o
```python
import os                           # M√≥dulo inteiro
from datetime import datetime       # Fun√ß√£o espec√≠fica
import pandas as pd                 # Com alias
```

##### Bibliotecas Comuns
| Biblioteca | Uso |
|------------|-----|
| `os` | Vari√°veis de ambiente, caminhos |
| `datetime` | Manipula√ß√£o de datas |
| `json` | Leitura/escrita de JSON |
| `logging` | Logs de execu√ß√£o |
| `pandas` | Manipula√ß√£o de dados |
| `boto3` | Integra√ß√£o AWS (S3) |

##### Exemplo: datetime
```python
from datetime import datetime, timedelta

agora = datetime.now()
ontem = agora - timedelta(days=1)
formatado = agora.strftime("%Y-%m-%d")   # "2025-01-13"
```

##### Exemplo: os
```python
import os

# Vari√°veis de ambiente
usuario = os.getenv("DB_USER", "default")

# Caminhos
caminho = os.path.join("pasta", "arquivo.txt")
```

---


### 1.2.2. Recursos da Linguagem (comprehension, decorators, context manager) {#122-recursos-da-linguagem-comprehension-decorators-context-manager}


> Os t√≥picos a seguir aparecem frequentemente em c√≥digo de DAGs e scripts de extra√ß√£o.

---

#### Comprehension

**Quando usar:** Transformar ou filtrar uma lista/dicion√°rio de forma compacta.

```python
# List comprehension - criar lista transformada
numeros = [1, 2, 3, 4, 5]
dobros = [x * 2 for x in numeros]           # [2, 4, 6, 8, 10]

# Com filtro - criar lista filtrada
pares = [x for x in numeros if x % 2 == 0]  # [2, 4]

# Dict comprehension
nomes = ["ana", "bob"]
tamanhos = {nome: len(nome) for nome in nomes}  # {"ana": 3, "bob": 3}
```

**Exemplo real (extrair nomes de colunas do cursor):**
```python
colunas = [desc[0] for desc in cursor.description]
```

---

#### Context Manager (with)

**Quando usar:** Abrir arquivos, conex√µes ou recursos que precisam ser fechados.

```python
# Arquivo - fecha automaticamente ao sair do bloco
with open("dados.csv", "r") as f:
    conteudo = f.read()

# M√∫ltiplos recursos
with open("entrada.txt") as entrada, open("saida.txt", "w") as saida:
    saida.write(entrada.read())
```

**Por que usar:** Evita esquecer de fechar arquivos/conex√µes, mesmo se der erro.

---

#### Decorators

**O que √©:** Marcador (`@`) que modifica o comportamento de uma fun√ß√£o.

```python
@task
def extrair_dados():
    pass
```

**Na pr√°tica:** Voc√™ vai *ler* e *usar* decorators prontos, n√£o criar. Quando vir `@algo` antes de uma fun√ß√£o, saiba que ela est√° sendo "decorada" com comportamento extra.

---

#### Argumentos `**kwargs`

**O que √©:** Captura argumentos nomeados extras como dicion√°rio.

```python
def funcao(obrigatorio, **kwargs):
    print(obrigatorio)
    print(kwargs)        # Dicion√°rio com argumentos extras

funcao("valor", nome="Jo√£o", idade=30)
# Sa√≠da:
# valor
# {"nome": "Jo√£o", "idade": 30}
```

**Uso comum (acessar contexto do Airflow):**
```python
def minha_task(**context):
    data_execucao = context["ds"]
    params = context["params"]
```

---

#### Type Hints

**O que √©:** Indica tipos esperados. N√£o obriga, apenas documenta.

```python
def somar(a: int, b: int) -> int:
    return a + b

def processar(nome: str, ativo: bool = True) -> dict:
    return {"nome": nome, "ativo": ativo}
```

**Tipos comuns:** `str`, `int`, `float`, `bool`, `list`, `dict`, `Optional[str]`

---

#### Unpacking

**Quando usar:** Extrair valores de tuplas, listas ou dicion√°rios em vari√°veis separadas.

```python
# Tupla/Lista
coordenadas = (10, 20)
x, y = coordenadas                # x=10, y=20

# Em loop com tuplas
pares = [("a", 1), ("b", 2)]
for letra, numero in pares:
    print(f"{letra}: {numero}")

# Dicion√°rio (.items())
config = {"host": "localhost", "porta": 5432}
for chave, valor in config.items():
    print(f"{chave} = {valor}")
```

---


### 1.2.3. Pandas para An√°lise Explorat√≥ria {#123-pandas-para-an√°lise-explorat√≥ria}


> Biblioteca para an√°lise e manipula√ß√£o de dados tabulares.

---

#### Criar DataFrame

```python
import pandas as pd

# De dicion√°rio
df = pd.DataFrame({
    "nome": ["Ana", "Bob", "Carol"],
    "idade": [25, 30, 28],
    "salario": [5000, 6000, 5500]
})

# De arquivo
df = pd.read_csv("dados.csv")
df = pd.read_excel("dados.xlsx")
```

---

#### Conhecer os Dados

```python
df.head()              # Primeiras 5 linhas
df.tail()              # √öltimas 5 linhas
df.shape               # (linhas, colunas)
df.columns             # Nomes das colunas
df.dtypes              # Tipos de cada coluna
df.info()              # Resumo geral
df.describe()          # Estat√≠sticas num√©ricas
```

---

#### Selecionar e Filtrar

```python
# Sele√ß√£o
df["nome"]             # Uma coluna (Series)
df[["nome", "idade"]]  # M√∫ltiplas colunas (DataFrame)
df.iloc[0]             # Primeira linha por √≠ndice
df.iloc[0:3]           # Linhas 0, 1, 2

# Filtros
df[df["idade"] > 25]                              # Idade maior que 25
df[df["nome"] == "Ana"]                           # Nome igual a Ana
df[(df["idade"] > 25) & (df["salario"] > 5000)]   # M√∫ltiplas condi√ß√µes
```

---

#### Agregar

```python
# Valores √∫nicos
df["salario"].sum()           # Soma
df["salario"].mean()          # M√©dia
df["salario"].max()           # M√°ximo
df["salario"].min()           # M√≠nimo
df["nome"].count()            # Contagem
df["nome"].nunique()          # Quantidade de valores √∫nicos
df["cargo"].value_counts()    # Frequ√™ncia de cada valor

# Group By
df.groupby("departamento")["salario"].mean()      # M√©dia por grupo
df.groupby("departamento").agg({
    "salario": "mean",
    "nome": "count"
})
```

---

#### Tratar Nulos

```python
df.isnull().sum()         # Conta nulos por coluna
df.dropna()               # Remove linhas com nulo
df.fillna(0)              # Substitui nulos por 0
```

---

#### Exportar

```python
df.to_csv("saida.csv", index=False)
df.to_excel("saida.xlsx", index=False)
```

---

##### Teste seu Conhecimento

**O que esse c√≥digo retorna?**

```python
dados = [
    {"nome": "Ana", "ativo": True},
    {"nome": "Bob", "ativo": False},
    {"nome": "Carol", "ativo": True}
]

resultado = [x["nome"] for x in dados if x["ativo"]]
```

<details>
<summary>Ver resposta</summary>

```python
["Ana", "Carol"]
```
Explica√ß√£o: List comprehension que filtra apenas os dicion√°rios onde `ativo` √© `True` e extrai o valor de `"nome"`.

</details>

---

# 2. Conceitos e Ciclo de Vida

## 2.1. Ciclo de Vida da An√°lise de Dados

Framework conceitual para o processo de an√°lise de dados - Pipeline Audit√°vel End-to-End.

### 2.1.1. Etapas do Ciclo (6 etapas) {#211-etapas-do-ciclo-6-etapas}


```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Defini√ß√£o   ‚îÇ   ‚îÇ 2. An√°lise     ‚îÇ   ‚îÇ 3. Prepara√ß√£o  ‚îÇ   ‚îÇ 4. Modelagem   ‚îÇ   ‚îÇ 5. Valida√ß√£o   ‚îÇ   ‚îÇ 6. Power BI    ‚îÇ
‚îÇ do Problema    ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ Explorat√≥ria   ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ e Transforma√ß√£o‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ Dimensional    ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ de Integridade ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ                ‚îÇ
‚îÇ de Neg√≥cio     ‚îÇ   ‚îÇ                ‚îÇ   ‚îÇ                ‚îÇ   ‚îÇ                ‚îÇ   ‚îÇ                ‚îÇ   ‚îÇ                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                    ‚îÇ                    ‚îÇ                    ‚îÇ                    ‚îÇ                    ‚îÇ
     ‚ñº                    ‚ñº                    ‚ñº                    ‚ñº                    ‚ñº                    ‚ñº
 ‚Ä¢ Objetivos         ‚Ä¢ Mapeamento         ‚Ä¢ Staging Layer      ‚Ä¢ Marts Layer        ‚Ä¢ Totaliza√ß√£o       ‚Ä¢ Modelagem 1:N
 ‚Ä¢ KPIs              SQL Server           dbt                  dbt                  Tripla              ‚Ä¢ DAX
 ‚Ä¢ Stakeholders      ‚Ä¢ Cardinalidades     ‚Ä¢ Padroniza√ß√£o       ‚Ä¢ Fatos              ‚Ä¢ Origem ‚Üí dbt      ‚Ä¢ Dashboards
                     ‚Ä¢ Anomalias          ‚Ä¢ Limpeza            ‚Ä¢ Dimens√µes          ‚Üí SQL Server
                                          ‚Ä¢ Joins              ‚Ä¢ Star Schema
                                          ‚Ä¢ Testes
```


### 2.1.2. Detalhamento das Etapas {#212-detalhamento-das-etapas}


| Etapa | Descri√ß√£o | Ferramentas/Atividades |
|-------|-----------|------------------------|
| **1. Defini√ß√£o do Problema** | Identificar a pergunta de neg√≥cio | Objetivos, KPIs, Stakeholders |
| **2. An√°lise Explorat√≥ria** | Entender os dados dispon√≠veis | Mapeamento SQL Server, Cardinalidades, Anomalias |
| **3. Prepara√ß√£o e Transforma√ß√£o** | Limpar e padronizar dados | Staging Layer dbt, Padroniza√ß√£o, Limpeza, Joins, Testes |
| **4. Modelagem Dimensional** | Criar modelo anal√≠tico | Marts Layer dbt, Fatos, Dimens√µes, Star Schema |
| **5. Valida√ß√£o de Integridade** | Garantir qualidade | Totaliza√ß√£o Tripla: Origem ‚Üí dbt ‚Üí SQL Server |
| **6. Power BI** | Visualizar e entregar | Modelagem 1:N, DAX, Dashboards |

---

## 2.2. Arquitetura ELT

Documenta√ß√£o da arquitetura de dados implementada na Barra Mansa Alimentos.

### 2.2.1. Vis√£o Geral do Processo {#221-vis√£o-geral-do-processo}


O pipeline de dados est√° estruturado para processar informa√ß√µes dos sistemas corporativos e industriais (ERP Sapiens e Sistema AIS) at√© a disponibiliza√ß√£o em dashboards no Power BI Service.

#### Arquitetura do Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FONTES    ‚îÇ     ‚îÇ  EXTRA√á√ÉO &      ‚îÇ     ‚îÇ           DATA WAREHOUSE                ‚îÇ     ‚îÇ  VISUALIZA√á√ÉO   ‚îÇ
‚îÇ             ‚îÇ     ‚îÇ  CARGA (EL)      ‚îÇ     ‚îÇ          Amazon Redshift                ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ ERP Sapiens ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                  ‚îÇ     ‚îÇ                                         ‚îÇ     ‚îÇ  Power BI       ‚îÇ
‚îÇ Sistema AIS ‚îÇ     ‚îÇ Scripts Python   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Raw    ‚Üí Source  ‚Üí Staging ‚Üí Marts    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Service        ‚îÇ
‚îÇ             ‚îÇ     ‚îÇ Apache Airflow   ‚îÇ     ‚îÇ  Layer    Layer     Layer     Layer     ‚îÇ     ‚îÇ  Dashboards     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  (Dados   (Padro-   (Limpeza) (Dimens√µes‚îÇ     ‚îÇ  Corporativos   ‚îÇ
                                             ‚îÇ  Brutos)  niza√ß√£o)            & Fatos)  ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```


### 2.2.2. Componentes Principais (fontes, EL, transforma√ß√£o, camadas, visualiza√ß√£o) {#222-componentes-principais-fontes-el-transforma√ß√£o-camadas-visualiza√ß√£o}


#### Fontes de Dados
- **ERP Sapiens** - Sistema corporativo
- **Sistema AIS** - Sistema industrial

#### Extra√ß√£o e Carga (EL)
- **Scripts Python** - Extra√ß√£o dos dados das fontes
- **Apache Airflow** - Orquestra√ß√£o dos processos

#### Transforma√ß√£o (T) - Processamento H√≠brido

| Tipo | Ferramenta | Frequ√™ncia | Uso |
|------|------------|------------|-----|
| Batch | dbt Cloud | V√°rias execu√ß√µes/dia | Transforma√ß√µes programadas |
| Near Real-Time (NRT) | Apache Airflow + Scripts Python | Cont√≠nuo | Dados cr√≠ticos |

#### Camadas do Data Warehouse

| Camada | Fun√ß√£o |
|--------|--------|
| **Raw Layer** | Dados brutos sem transforma√ß√£o |
| **Source Layer** | Padroniza√ß√£o de tipos e nomenclatura |
| **Staging Layer** | Limpeza, joins e testes |
| **Marts Layer** | Dimens√µes e Fatos prontos para consumo |

#### Visualiza√ß√£o
- **Power BI Service** - Dashboards corporativos para todas as √°reas

---

---

# 3. Ambiente e Ferramentas

## 3.1. WSL/Linux

### 3.1.1. Navega√ß√£o {#311-navega√ß√£o}

```bash
pwd                 # Mostra diret√≥rio atual
ls                  # Lista arquivos
ls -la              # Lista com detalhes e ocultos
cd pasta            # Entra na pasta
cd ..               # Volta um n√≠vel
cd ~                # Vai para home
```

### 3.1.2. Gerenciamento de Arquivos {#312-gerenciamento-de-arquivos}

```bash
mkdir pasta         # Cria pasta
touch arquivo.txt   # Cria arquivo vazio
cp origem destino   # Copia
mv origem destino   # Move/renomeia
rm arquivo          # Remove arquivo
rm -rf pasta        # Remove pasta e conte√∫do
```


### 3.1.3. Gerenciamento de Pacotes {#313-gerenciamento-de-pacotes}

```bash
sudo apt update             # Atualiza lista de pacotes
sudo apt upgrade            # Atualiza pacotes instalados
sudo apt install pacote     # Instala pacote
sudo apt remove pacote      # Remove pacote
```


## 3.2. Python (Ambiente)

### 3.2.1. Criar e Ativar Ambiente Virtual {#321-criar-e-ativar-ambiente-virtual}

```bash
python -m venv nome_env     # Cria ambiente
source nome_env/bin/activate    # Ativa (Linux/WSL)
```


### 3.2.2. Gerenciar Depend√™ncias {#322-gerenciar-depend√™ncias}

```bash
pip install pacote          # Instala pacote
pip install -r requirements.txt   # Instala do arquivo
pip freeze > requirements.txt     # Exporta depend√™ncias
pip list                    # Lista instalados
```

### Desativar
```bash
deactivate                  # Sai do ambiente virtual
```


## 3.3. VS Code

### 3.3.1. Extens√µes Recomendadas {#331-extens√µes-recomendadas}

| Extens√£o | Uso |
|----------|-----|
| Python | Intellisense e debug |
| Pylance | Autocomplete avan√ßado |
| dbt Power User | Navega√ß√£o, preview e lineage dbt |
| GitLens | Hist√≥rico e blame |
| Remote - WSL | Desenvolvimento no WSL |


### 3.3.2. Atalhos Principais {#332-atalhos-principais}

| Atalho | A√ß√£o |
|--------|------|
| `Ctrl + Shift + P` | Command Palette |
| `Ctrl + P` | Buscar arquivo |
| `Ctrl + B` | Toggle sidebar |
| `Ctrl + `` ` | Terminal integrado |
| `Ctrl + Shift + F` | Buscar no projeto |
| `Ctrl + D` | Seleciona pr√≥xima ocorr√™ncia |
| `Alt + ‚Üë/‚Üì` | Move linha |

---

## 3.4. Git

### 3.4.1. Comandos B√°sicos {#341-comandos-b√°sicos}

| Comando | Descri√ß√£o |
|---------|-----------|
| `git init` | Inicializa o reposit√≥rio |
| `git status` | Verifica status dos arquivos |
| `git add .` | Adiciona altera√ß√µes ao stage |
| `git commit -m` | Cria um commit |
| `git branch` | Lista branches |
| `git checkout -b` | Cria nova branch |
| `git pull` | Atualiza o c√≥digo local |
| `git push` | Envia para o GitHub |


### 3.4.2. Desfazer Altera√ß√µes {#342-desfazer-altera√ß√µes}

```bash
git restore arquivo.sql            # Descarta altera√ß√µes n√£o staged
git restore --staged arquivo.sql   # Remove do stage (mant√©m altera√ß√£o)
git reset --soft HEAD~1            # Desfaz √∫ltimo commit (mant√©m altera√ß√µes)
git reset --hard HEAD~1            # Desfaz √∫ltimo commit (perde altera√ß√µes)
git clean -fd                      # Remove arquivos n√£o rastreados
git stash                          # Guarda altera√ß√µes temporariamente
git stash pop                      # Recupera altera√ß√µes guardadas
git merge --abort                  # Cancela merge em andamento
```


### 3.4.3. Resolu√ß√£o de Conflitos {#343-resolu√ß√£o-de-conflitos}

```bash
git merge --abort                  # Cancela merge em andamento
```

*Para conflitos detalhados, edite os arquivos manualmente e fa√ßa commit ap√≥s resolver.*

### 3.4.4. Boas Pr√°ticas {#344-boas-pr√°ticas}


### 1Ô∏è‚É£ Atualizar branch principal
```bash
git checkout main
git pull
```

### 2Ô∏è‚É£ Criar nova branch
```bash
git checkout -b nome-da-branch
```

**Padr√£o para branches:** `feature/`, `fix/`, `docs/`

### 3Ô∏è‚É£ Desenvolver e testar
```bash
# Editar arquivos no VS Code
dbt build -s nome_do_modelo        # Executa e testa
```

### 4Ô∏è‚É£ Commitar e enviar
```bash
git status
git add .
git commit -m "feat: cria modelo de vendas"
git push origin -u nome-da-branch
```

### 5Ô∏è‚É£ Abrir Pull Request no GitHub

---

## 3.4.3 Resolu√ß√£o de Conflitos

### Quando Acontece
Conflitos ocorrem quando duas branches alteram as mesmas linhas.

### Passo a Passo
```bash
git pull origin main               # Atualiza sua branch
git status                         # Identifica arquivos em conflito
```


## 3.5 Fluxo de Desenvolvimento

### 3.5.1. Git ‚Üí dbt ‚Üí GitHub (passo a passo) {#351-git--dbt--github-passo-a-passo}

Abrir arquivo e resolver:
```
<<<<<<< HEAD
seu c√≥digo
=======
c√≥digo da main
>>>>>>> main
```

Remover marcadores, escolher c√≥digo correto, depois:
```bash
git add arquivo_resolvido.sql
git commit -m "fix: resolve conflito"
git push
```

### Cancelar Merge
```bash
git merge --abort                  # Volta ao estado anterior
```

---

## Boas Pr√°ticas

- ‚úÖ Commits pequenos e objetivos
- ‚úÖ Mensagens claras: `feat:`, `fix:`, `docs:`
- ‚úÖ Sempre trabalhar com branches
- ‚úÖ `git pull` antes de come√ßar o dia
- ‚úÖ `dbt build` antes do commit
- ‚úÖ Resolver conflitos imediatamente

---

Fluxo padr√£o de desenvolvimento local at√© publica√ß√£o no GitHub. Este guia descreve o processo oficial de trabalho com Git e dbt, utilizado para cria√ß√£o, versionamento e publica√ß√£o de modelos no GitHub.

### Fluxo Padr√£o de Desenvolvimento (Git ‚Üí dbt ‚Üí GitHub)

#### 1Ô∏è‚É£ Atualizar a branch principal
```bash
git checkout main
git pull
```

#### 2Ô∏è‚É£ Criar uma nova branch
```bash
git checkout -b nome-da-branch
```

**Padr√£o recomendado para branches:**
- `feature/nome-do-modelo`
- `fix/correcao-imposto`
- `docs/atualizacao-documentacao`

#### 3Ô∏è‚É£ Realizar as altera√ß√µes

Criar ou editar arquivos no VS Code. Exemplos de arquivos: `.sql`, `.yml`, `.md`

#### 4Ô∏è‚É£ Executar o dbt localmente (obrigat√≥rio)

---

#### 6Ô∏è‚É£ Verificar altera√ß√µes realizadas
```bash
git status
```

#### 7Ô∏è‚É£ Adicionar arquivos ao stage
```bash
git add .
```

#### 8Ô∏è‚É£ Criar o commit
```bash
git commit -m "mensagem clara e objetiva"
```

**Boas pr√°ticas de commit:**
```bash
git commit -m "feat: cria modelo de vendas"
git commit -m "fix: ajusta calculo de ICMS"


```

#### 9Ô∏è‚É£ Enviar a branch para o GitHub
```bash
git push origin -u nome-da-branch
```

Ap√≥s a primeira vez:
```bash
git push
```

#### üîü Abrir Pull Request no GitHub
1. Acesse o reposit√≥rio no GitHub
2. Clique em **Compare & Pull Request**
3. Preencha a descri√ß√£o
4. Solicite revis√£o


```bash
# Executar seed normalmente
dbt seed -s nome_do_modelo

# Executar seed com full refresh (substitui todos os dados)
dbt seed -s nome_do_modelo --full-refresh
```

### Fluxo Di√°rio Mais Utilizado

```bash
git status
git add .
git commit -m "mensagem"
git push
```

### Comandos Git Mais Usados

| Comando | Descri√ß√£o |
|---------|-----------|
| `git init` | Inicializa o reposit√≥rio |
| `git status` | Verifica o status dos arquivos |
| `git add .` | Adiciona altera√ß√µes ao stage |
| `git commit -m` | Cria um commit |
| `git branch` | Lista branches |
| `git checkout -b` | Cria nova branch |
| `git pull` | Atualiza o c√≥digo local |
| `git push` | Envia para o GitHub |

### Boas Pr√°ticas

- ‚úÖ Commits pequenos e objetivos
- ‚úÖ Mensagens claras e padronizadas
- ‚úÖ Sempre trabalhar com branches
- ‚úÖ Executar `git pull` antes de subir altera√ß√µes
- ‚úÖ Rodar `dbt run` antes do commit

---

# 4. Stack de Dados

## 4.1 AWS no Contexto Barra Mansa

Vis√£o geral dos servi√ßos AWS utilizados no pipeline de dados.

---

## 4.1. Vis√£o Geral

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SQL Server  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ     S3      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ  Redshift   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ  Power BI   ‚îÇ
‚îÇ   (Fonte)   ‚îÇ      ‚îÇ (Staging)   ‚îÇ      ‚îÇ    (DW)     ‚îÇ      ‚îÇ   (Consumo) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ     EC2     ‚îÇ

### 4.2.2. Camadas de Dados {#422-camadas-de-dados}

                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 4.1.2 S3 (Simple Storage Service)

**O que √©:** Armazenamento de arquivos na nuvem (buckets e objetos).

**Uso na Barra Mansa:** √Årea de staging tempor√°ria. Os arquivos CSV/GZIP ficam no S3 entre a extra√ß√£o (SQL Server) e a carga (Redshift).

**Estrutura:**
```
s3://bm-airflow/
‚îî‚îÄ‚îÄ comercial/
    ‚îú‚îÄ‚îÄ tabela1_incremental_temp.csv.gz
    ‚îî‚îÄ‚îÄ tabela2_incremental_temp.csv.gz
```

---

## 4.1.3. EC2 (Elastic Compute Cloud)

**O que √©:** Servidores virtuais na AWS.

**Uso na Barra Mansa:** M√°quina onde roda o Apache Airflow, executando as DAGs de extra√ß√£o e carga.

---

## 4.1.4. Redshift

**O que √©:** Data Warehouse colunar da AWS, otimizado para consultas anal√≠ticas (OLAP).

**Uso na Barra Mansa:** Destino final dos dados. O Power BI conecta aqui para os dashboards.

---

### Distribution Style

Define como os dados s√£o distribu√≠dos entre os n√≥s do cluster.

| Estilo | Quando usar | Exemplo |
|--------|-------------|---------|
| **KEY** | Tabelas grandes com JOINs frequentes | Fatos (distribui pela FK) |
| **ALL** | Tabelas pequenas usadas em muitos JOINs | Dimens√µes (replica em todos os n√≥s) |
| **EVEN** | Tabelas sem padr√£o claro de JOIN | Padr√£o quando n√£o especificado |

```sql
CREATE TABLE fato_vendas (
    id_venda INT,
    id_produto INT,
    valor DECIMAL
)
DISTSTYLE KEY
DISTKEY (id_produto);
```

---

### Sort Key

Define a ordem f√≠sica dos dados no disco. Acelera filtros no `WHERE`.

**Regra pr√°tica:** Use a coluna mais filtrada (geralmente data).

```sql
CREATE TABLE fato_vendas (
    id_venda INT,
    data_venda DATE,
    valor DECIMAL
)
SORTKEY (data_venda);
```

---

### COPY

Comando para carga em massa do S3 para Redshift. Muito mais r√°pido que INSERT.

```sql
COPY minha_tabela
FROM 's3://bm-airflow/comercial/arquivo.csv.gz'
IAM_ROLE 'arn:aws:iam::123456789:role/RedshiftRole'
DELIMITER ','
GZIP
IGNOREHEADER 1
CSV;
```

---

### EXPLAIN

Mostra o plano de execu√ß√£o da query antes de rodar. √ötil para identificar gargalos.

```sql
EXPLAIN
SELECT * FROM fato_vendas WHERE data_venda > '2025-01-01';
```

**O que observar:**
- `DS_DIST_*` ‚Üí redistribui√ß√£o de dados (lento)
- `Seq Scan` ‚Üí leitura sequencial (pode ser lento em tabelas grandes)
- Custo alto ‚Üí query pode demorar

---

### Troubleshooting

#### Ver erros de COPY
```sql
SELECT *
FROM stl_load_errors
ORDER BY starttime DESC
LIMIT 10;
```

#### Ver queries em execu√ß√£o
```sql
SELECT 
    pid,
    user_name,
    starttime,
    query
FROM stv_recents
WHERE status = 'Running';
```

#### Ver transa√ß√µes ativas/travadas
```sql
SELECT 
    txn_owner,
    txn_start,
    lock_mode,
    relation
FROM svv_transactions
WHERE lockable_object_type = 'relation';
```

#### Derrubar processo travado
```sql
-- Primeiro: identifique o PID com as queries acima
-- Depois: termine o processo
SELECT pg_terminate_backend(PID_AQUI);
```

‚ö†Ô∏è **Cuidado:** S√≥ derrube processos que voc√™ tem certeza que est√£o travados.

---

### Manuten√ß√£o

```sql
-- Reorganiza dados ap√≥s DELETEs (libera espa√ßo)
VACUUM tabela;

-- Atualiza estat√≠sticas para o otimizador
ANALYZE tabela;
```

**Quando rodar:** Ap√≥s grandes cargas incrementais ou deletes em massa.

---

# 4.2. dbt (Data Build Tool)

Ferramenta de transforma√ß√£o de dados que roda SQL no warehouse.

---

## 4.2.1. Estrutura do Projeto

```
dbt_bm/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_clientes.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_vendas.sql
‚îÇ   ‚îî‚îÄ‚îÄ marts/
‚îÇ       ‚îú‚îÄ‚îÄ dim_clientes.sql
‚îÇ       ‚îî‚îÄ‚îÄ fato_vendas.sql
‚îú‚îÄ‚îÄ seeds/
‚îÇ   ‚îî‚îÄ‚îÄ mapeamento_filiais.csv
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îî‚îÄ‚îÄ grant_permissions.sql
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ dbt_project.yml
‚îî‚îÄ‚îÄ packages.yml
```

| Pasta | Conte√∫do |
|-------|----------|
| `models/` | Arquivos SQL das transforma√ß√µes |
| `seeds/` | CSVs carregados como tabelas |
| `macros/` | Fun√ß√µes reutiliz√°veis (ex: permiss√µes) |
| `tests/` | Testes customizados |

---

## 4.2.2. Camadas de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Raw   ‚îÇ ‚îÄ‚îÄ ‚îÇ Source  ‚îÇ ‚îÄ‚îÄ ‚îÇ      Staging        ‚îÇ ‚îÄ‚îÄ ‚îÇ  Marts  ‚îÇ
‚îÇ         ‚îÇ    ‚îÇ         ‚îÇ    ‚îÇ (staging + intermed)‚îÇ    ‚îÇ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  Airflow        dbt              dbt                      dbt
  (EL)        (padroniza)     (limpa, join)          (dims e fatos)
```

| Camada | Schema Redshift | Respons√°vel | Objetivo |
|--------|-----------------|-------------|----------|
| **Raw** | `airbyte_raw` | Airflow | Dados brutos do SQL Server |
| **Source** | `source` | dbt | Padroniza√ß√£o de nomes e tipos |
| **Staging** | `staging` | dbt | Limpeza, joins, regras de neg√≥cio |
| **Marts** | `marts` | dbt | Dimens√µes e Fatos para consumo |

---

### 4.2.3. Materializa√ß√µes {#423-materializa√ß√µes}

Define como o modelo √© persistido no banco.

| Tipo | O que faz | Quando usar |
|------|-----------|-------------|
| **table** | Cria tabela f√≠sica (DROP + CREATE) | Padr√£o na BM |
| **view** | Cria view (sempre recalcula) | Dados leves, pouca transforma√ß√£o |
| **incremental** | Insere apenas novos registros | Tabelas grandes com coluna de data |
| **ephemeral** | N√£o cria nada (CTE) | Modelo auxiliar usado por outros |

**Configurar no modelo:**
```sql
{{ config(materialized='table') }}

SELECT * FROM {{ ref('stg_clientes') }}
```

**Ou no `dbt_project.yml` (aplica para pasta inteira):**
```yaml
models:
  bm_dbt:
    staging:
      materialized: table
    marts:
      materialized: table
```

---

### 4.2.4. Sources e Refs {#424-sources-e-refs}

#### source() - Referencia tabelas externas (Raw)
```sql
-- models/staging/stg_clientes.sql
SELECT *
FROM {{ source('airbyte_raw', 'e095for') }}
```

#### ref() - Referencia outros modelos dbt
```sql
-- models/marts/dim_clientes.sql
SELECT *
FROM {{ ref('stg_clientes') }}
```

**Por que usar:** dbt monta a ordem de execu√ß√£o automaticamente (DAG).

---

#### Declarar Sources (schema.yml)

```yaml
# models/staging/schema.yml
version: 2

sources:
  - name: airbyte_raw
    database: producao
    schema: airbyte_raw
    tables:
      - name: e095for
        description: "Cadastro de fornecedores"
      - name: e440nfc
        description: "Notas fiscais de compra"
```

---

### 4.2.5. Testes {#425-testes}

Validam qualidade dos dados. Rodam com `dbt test`.

#### Testes Nativos

| Teste | Valida |
|-------|--------|
| `unique` | Valores √∫nicos (sem duplicados) |
| `not_null` | Sem valores nulos |
| `accepted_values` | Valores dentro de lista permitida |
| `relationships` | FK existe na tabela referenciada |

#### Configurar no schema.yml

```yaml
# models/marts/schema.yml
version: 2

models:
  - name: dim_clientes
    columns:
      - name: id_cliente
        tests:
          - unique
          - not_null
      - name: status
        tests:
          - accepted_values:
              values: ['ativo', 'inativo']
```

---

### 4.2.6. Jinja B√°sico {#426-jinja-b√°sico}

dbt usa Jinja para SQL din√¢mico.

#### Sintaxe

| Sintaxe | Uso |
|---------|-----|
| `{{ }}` | Imprime valor |
| `{% %}` | L√≥gica (if, for) |
| `{# #}` | Coment√°rio |

#### Fun√ß√µes Comuns

```sql
-- Refer√™ncias
{{ ref('stg_clientes') }}
{{ source('airbyte_raw', 'e095for') }}

-- Vari√°veis
{{ var('data_inicio', '2025-01-01') }}

-- Condicional
{% if target.name == 'prod' %}
    schema_producao
{% else %}
    schema_dev
{% endif %}
```

---

### Macro de Permiss√µes (BM)

Macro que concede permiss√µes ap√≥s criar tabelas. Roda automaticamente.

```sql
-- macros/grant_permissions.sql
{% macro grant_permissions() %}
    GRANT SELECT ON ALL TABLES IN SCHEMA {{ target.schema }} TO GROUP leitores;
{% endmacro %}
```

**Configurar para rodar ap√≥s cada modelo:**
```yaml
# dbt_project.yml
on-run-end:
  - "{{ grant_permissions() }}"
```

---

### Lineage (Grafo de Depend√™ncias)

Visualiza a rela√ß√£o entre modelos.

### Gerar e Visualizar
```bash
dbt docs generate    # Gera documenta√ß√£o
dbt docs serve       # Abre no navegador
```

### Como Usar
1. Clique no √≠cone de grafo (canto inferior direito)
2. Busque um modelo
3. Veja depend√™ncias (upstream) e dependentes (downstream)

**√ötil para:** Entender impacto de mudan√ßas, debugar erros em cascata.

---

### 4.2.7. Comandos dbt {#427-comandos-dbt}


#### Execu√ß√£o
```bash
dbt run                            # Executa todos os modelos
dbt run -s nome_do_modelo          # Executa modelo espec√≠fico
dbt run -s +nome_do_modelo         # Modelo + filhos (downstream)
dbt run -s @nome_do_modelo         # Modelo + pais e filhos
```

#### Testes e Build
```bash
dbt test                           # Executa todos os testes
dbt test -s nome_do_modelo         # Testa modelo espec√≠fico
dbt build                          # Executa run + test
dbt build -s nome_do_modelo        # Build de modelo espec√≠fico
```

#### Seeds e Depend√™ncias
```bash
dbt seed                           # Carrega todos os seeds
dbt seed -s nome_do_seed           # Carrega seed espec√≠fico
dbt seed --full-refresh            # Substitui todos os dados
dbt deps                           # Instala packages do packages.yml
```

#### Debug e Documenta√ß√£o
```bash
dbt debug                          # Verifica conex√£o e configura√ß√£o
dbt compile                        # Compila SQL sem executar
dbt compile -s nome_do_modelo      # Compila modelo espec√≠fico
dbt docs generate                  # Gera documenta√ß√£o
dbt docs serve                     # Abre documenta√ß√£o no navegador
```

---

## 4.3. Airflow

Orquestrador de pipelines de dados.

### 4.3.1. Conceitos Essenciais {#431-conceitos-essenciais}


**Airflow** agenda, executa e monitora pipelines de dados.

**Por que usar (vs cron/scripts):**

| Cron/Scripts | Airflow |
|--------------|---------|
| Sem visualiza√ß√£o | Interface web com fluxo visual |
| Depend√™ncias manuais | Depend√™ncias autom√°ticas |
| Logs espalhados | Logs centralizados |
| Retry manual | Retry autom√°tico |

---


```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Task  ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ Task  ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ Task  ‚îÇ
‚îÇ   A   ‚îÇ      ‚îÇ   B   ‚îÇ      ‚îÇ   C   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
 extrair       transformar     carregar
```

| Conceito | O que √© |
|----------|---------|
| **DAG** | Fluxo de tarefas (grafo sem ciclos) |
| **Task** | Unidade de trabalho |
| **Depend√™ncia** | Ordem de execu√ß√£o |

---


### 4.3.2. Operadores {#432-operadores}


Operador define **o que** a task faz.

| Operador | O que faz |
|----------|-----------|
| `@task` | Executa fun√ß√£o Python (padr√£o) |
| `BranchPythonOperator` | Decide qual caminho seguir |
| `EmptyOperator` | Placeholder |
| `TriggerDagRunOperator` | Dispara outra DAG |

**`@task`** √© um atalho para `PythonOperator`:

```python
# Com decorator (recomendado)
@task
def extrair():
    return dados

# Equivalente
PythonOperator(task_id="extrair", python_callable=extrair_func)
```

---

### 4.3.3. Anatomia de uma DAG {#433-anatomia-de-uma-dag}

```python
from airflow import DAG
from airflow.decorators import task
import pendulum

with DAG(
    dag_id="minha_dag",                        # Nome √∫nico
    start_date=pendulum.datetime(2025, 1, 1),  # Data inicial
    schedule_interval="0 8 * * *",             # Quando roda (cron)
    catchup=False,                             # N√£o executa passadas
    tags=["exemplo"],                          # Categoriza√ß√£o
) as dag:

    @task
    def extrair():
        return "dados"

    @task
    def carregar(dados):
        print(dados)

    # Depend√™ncia: extrair ‚Üí carregar
    resultado = extrair()
    carregar(resultado)
```

---

### 4.3.4. Hooks e Conex√µes {#434-hooks-e-conex√µes}

**Hook** = conector para sistemas externos.

```python
from airflow.providers.microsoft.mssql.hooks.mssql import MsSqlHook
from airflow.providers.postgres.hooks.postgres import PostgresHook

# SQL Server
hook = MsSqlHook(mssql_conn_id="mssql_bm_conn")
cursor = hook.get_conn().cursor()
cursor.execute("SELECT * FROM tabela")

# Redshift
hook = PostgresHook(postgres_conn_id="redshift_conn")
hook.run("TRUNCATE TABLE destino")
```

---

### 4.3.5. Recursos Intermedi√°rios {#435-recursos-intermedi√°rios}

####  Context e Params

**Context:** Informa√ß√µes da execu√ß√£o.

```python
@task
def minha_task(**context):
    data = context["ds"]           # Data execu√ß√£o
    params = context["params"]     # Par√¢metros passados
```

**Params:** Par√¢metros via UI/CLI.

```python
with DAG(
    params={"custom_tables": Param(default=[], type=["null", "array"])}
) as dag:
    ...

# Disparar: {"custom_tables": ["e640lct"]}
```

---

#### Controle de Fluxo

**TriggerRule:** Quando a task executa.

| Regra | Executa quando |
|-------|----------------|
| `ALL_SUCCESS` | Todas anteriores OK (padr√£o) |
| `ALL_DONE` | Todas finalizadas (sucesso ou falha) |

**AirflowSkipException:** Pula task sem falhar.

```python
from airflow.exceptions import AirflowSkipException

@task
def processar(tabela, **context):
    permitidas = context["params"].get("custom_tables", [])
    if permitidas and tabela not in permitidas:
        raise AirflowSkipException(f"{tabela} n√£o est√° na lista")
```

---

#### TaskGroups

Agrupa tasks visualmente.

```python
from airflow.utils.task_group import TaskGroup

with TaskGroup(group_id="vendas") as grupo:
    extrair_clientes()
    extrair_produtos()
```

---

#### Modulariza√ß√£o

**O que:** Separar DAG (orquestra√ß√£o) de l√≥gica (fun√ß√µes).

**Por que:** Reutiliza√ß√£o, testes, manuten√ß√£o.

**Como:**
```
dags/                    # Orquestra√ß√£o
scripts/python/          # Fun√ß√µes reutiliz√°veis
include/seed/            # Configura√ß√µes
```

```python
# DAG importa fun√ß√µes do m√≥dulo
from scripts.python.get_el_tasks import extract_upload

@task
def extrair(tabela):
    return extract_upload(tabela, S3_BUCKET)
```

---

#### Gera√ß√£o Din√¢mica

Cria tasks automaticamente a partir de lista ou arquivo.

##### Via Lista

```python
TABELAS = ["e095for", "e440nfc", "e660inv"]

for tabela in TABELAS:
    @task(task_id=f"process_{tabela}")
    def processar(t=tabela):
        extract_upload(t)
    processar()
```

**Resultado:** 3 tasks criadas automaticamente.

#### Via CSV

```python
import pandas as pd

df = pd.read_csv("nrt_dependencies.csv", sep=";")

for _, row in df.iterrows():
    criar_task(row["tabela_origem"], row["tabela_fato"])
```

**Vantagem:** Adicionar tabela = nova linha (sem mexer em c√≥digo).

---


### 4.3.6. Airflow na Barra Mansa {#436-airflow-na-barra-mansa}


#### Vis√£o Geral

**N√∫meros:** 70+ DAGs | 300+ tabelas | ~7k execu√ß√µes/dia

**Fluxo EL:**
```
SQL Server  ‚îÄ‚îÄ‚ñ∫  S3  ‚îÄ‚îÄ‚ñ∫  Redshift
 (fonte)      (staging)    (DW)
```

**Conex√µes:**

| Connection ID | Sistema |
|---------------|---------|
| `mssql_bm_conn` | SQL Server Sapiens |
| `mssql_bm_vetorh` | SQL Server VetorH |
| `mssql_bm_ais` | SQL Server AIS |
| `redshift_conn` | Redshift DW |

---

### Estrat√©gias de Carga

| Estrat√©gia | Opera√ß√£o | Uso | Schedule |
|------------|----------|-----|----------|
| **full_auto** | DROP ‚Üí CREATE ‚Üí COPY | Cadastros pequenos | Di√°rio |
| **full_manual** | DROP ‚Üí CREATE ‚Üí COPY | Tabelas grandes | Manual |
| **incremental** | DELETE (120 dias) ‚Üí COPY | Transa√ß√µes | Di√°rio |
| **nrt** | DELETE (60 dias) ‚Üí COPY | Dados cr√≠ticos | 5min |

**Por que full_auto vs full_manual?**
- Tabelas grandes travam se rodam junto
- Manual permite controle

**Janela incremental:**
- DELETE apaga √∫ltimos N dias
- COPY insere dados atualizados
- Evita duplica√ß√£o


### 4.3.7. Como Adicionar Nova Tabela {#437-como-adicionar-nova-tabela}


### DAGs Principais

#### job_sapiens_full_auto

Carga di√°ria de cadastros (48 tabelas pequenas).

```
Lista ‚Üí Para cada: DROP ‚Üí CREATE ‚Üí COPY
```

---

#### job_sapiens_full_manual

Carga manual de tabelas grandes (43 tabelas).

```
Lista ‚Üí Para cada: DROP ‚Üí CREATE ‚Üí COPY
```

Usado para carga inicial antes de ativar incremental.

---

#### job_sapiens_incremental

Carga incremental de transa√ß√µes (43 tabelas).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ job_sapiens_incremental                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Lista (tables.py)                          ‚îÇ
‚îÇ       ‚îÇ                                     ‚îÇ
‚îÇ       ‚ñº                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ dom_vendas ‚îÇ  ‚îÇ dom_fiscal ‚îÇ  ...       ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ e140nfv ‚îÇ  ‚îÇ ‚îú‚îÄ e660inv ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ e120ped ‚îÇ  ‚îÇ ‚îî‚îÄ e440nfc ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  Cada task: DELETE(120d) ‚Üí COPY            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

#### job_controladoria_financeira_nrt

Pipeline NRT: ingest√£o + transforma√ß√£o a cada 5min (60+ tabelas).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ job_controladoria_financeira_nrt                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                     ‚îÇ
‚îÇ  CSV (nrt_dependencies.csv)                         ‚îÇ
‚îÇ       ‚îÇ                                             ‚îÇ
‚îÇ       ‚ñº                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ ingestion    ‚îÇ      ‚îÇ transformation‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ e095for ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îú‚îÄ dim_fornec ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ e440nfc ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îî‚îÄ fato_compra‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                ‚îÇ                    ‚îÇ
‚îÇ                                ‚ñº                    ‚îÇ
‚îÇ                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ                        ‚îÇ log_execucao‚îÇ             ‚îÇ
‚îÇ                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                               ‚îÇ                     ‚îÇ
‚îÇ                               ‚ñº                     ‚îÇ
‚îÇ                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ                        ‚îÇtrigger_valid‚îÇ‚îÄ‚îÄ‚ñ∫ obs_dag  ‚îÇ
‚îÇ                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Arquivos de configura√ß√£o:**

| Arquivo | Conte√∫do |
|---------|----------|
| `nrt_dependencies.csv` | origem ‚Üí fato |
| `nrt_dominios_origem.csv` | dom√≠nio origem |
| `nrt_dominios.csv` | dom√≠nio fato |

---

### Como Adicionar Nova Tabela

#### Cen√°rio 1: Tabela Full (cadastro pequeno)

| Passo | Arquivo | A√ß√£o |
|-------|---------|------|
| 1 | `schema_sapiens.csv` | Adicionar colunas |
| 2 | `tables.py` | Adicionar em `TABELAS_FULL_AUTO` |

Pr√≥xima execu√ß√£o processa automaticamente.

---

#### Cen√°rio 2: Tabela Incremental (transacional)

| Passo | Arquivo | A√ß√£o |
|-------|---------|------|
| 1 | `schema_sapiens.csv` | Adicionar colunas |
| 2 | `incremental_config.csv` | Adicionar config |
| 3 | `tables.py` | Adicionar em `TABELAS_INCREMENTAL` |

```bash
# Carga inicial (obrigat√≥rio)
airflow dags trigger job_sapiens_full_manual \
    --conf '{"custom_tables": ["nova_tabela"]}'
```

Pr√≥ximas execu√ß√µes: incremental autom√°tico.

---

### 4.3.8. Opera√ß√£o {#438-opera√ß√£o}

#### Cen√°rio 3: Tabela NRT (transacional + transforma√ß√£o)

| Passo | Arquivo | A√ß√£o |
|-------|---------|------|
| 1-3 | (Cen√°rio 2) | Config raw incremental |
| 4 | `nrt_dependencies.csv` | Mapear origem ‚Üí fato |
| 5 | `nrt_dominios_origem.csv` | Dom√≠nio origem |
| 6 | `nrt_dominios.csv` | Dom√≠nio fato |
| 7 | `models/marts/` | Criar model dbt |

```bash
# Carga inicial raw
airflow dags trigger job_sapiens_full_manual \
    --conf '{"custom_tables": ["nova_tabela"]}'

# Testar transforma√ß√£o
dbt run -s fato_nova
```

---

#### Resumo

| Tipo | Cen√°rio | DAG |
|------|---------|-----|
| Cadastro pequeno | 1 | job_sapiens_full_auto |
| Transacional | 2 | job_sapiens_incremental |
| Transacional + dashboard | 3 | job_controladoria_nrt |

---

### Opera√ß√£o

#### Rodar Tabela Espec√≠fica

**UI:** Trigger DAG w/ config ‚Üí `{"custom_tables": ["e640lct"]}`

**CLI:**
```bash
airflow dags trigger job_sapiens_incremental \
    --conf '{"custom_tables": ["e640lct"]}'
```

#### Monitoramento

| Status | Cor | A√ß√£o |
|--------|-----|------|
| Success | üü¢ | OK |
| Failed | üî¥ | Ver logs ‚Üí Clear |
| Skipped | üü£ | Normal |
| Running | üü° | Aguardar |

#### Troubleshooting


## 4.4. Power BI

#### Ferramenta de visualiza√ß√£o e an√°lise de dados.

**Fluxo de trabalho:**
```
Conectar  ‚îÄ‚îÄ‚ñ∫  Modelar  ‚îÄ‚îÄ‚ñ∫  Visualizar  ‚îÄ‚îÄ‚ñ∫  Publicar
 (fontes)     (relacionar)    (gr√°ficos)      (compartilhar)
```

**Componentes:**
| Componente | Uso |
|------------|-----|
| Power Query | Conex√£o e transforma√ß√£o de dados |
| Modelo | Relacionamentos entre tabelas |
| Relat√≥rio | Cria√ß√£o de visuais |
| Servi√ßo | Publica√ß√£o e compartilhamento |

---

### 4.4.1. Conex√£o com Fontes {#441-conex√£o-com-fontes}

#### Redshift (conector nativo)
1. Obter Dados ‚Üí Banco de Dados ‚Üí Amazon Redshift
2. Informar servidor e banco
3. Credenciais ‚Üí Banco de Dados
4. Selecionar tabelas

#### Excel e CSV
1. Obter Dados ‚Üí Arquivo ‚Üí Excel / CSV
2. Selecionar arquivo
3. Escolher planilha/tabela

### 4.4.2. Modelagem de Dados {#442-modelagem-de-dados}

#### Google Sheets
1. Obter Dados ‚Üí Mais ‚Üí Google Sheets
2. Autenticar conta Google
3. Selecionar planilha

#### Import vs DirectQuery

| Modo | Dados | Quando usar |
|------|-------|-------------|
| **Import** | Carregados no Power BI | An√°lises complexas, melhor performance |
| **DirectQuery** | Consultados em tempo real | Dados muito grandes, sempre atualizados |

**Padr√£o BM:** Import (atualiza√ß√£o agendada).

---

### Modelagem de Dados

#### Star Schema

Modelo ideal para an√°lise: tabela **Fato** no centro, **Dimens√µes** ao redor.

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ dim_produto ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ dim_cliente ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ fato_vendas ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  dim_data   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ dim_vendedor‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Tipo | Conte√∫do | Exemplo |
|------|----------|---------|
| **Fato** | M√©tricas, transa√ß√µes | vendas, sa√≠das, lan√ßamentos |
| **Dimens√£o** | Atributos descritivos | produto, cliente, data |


### 4.4.3. DAX Intermedi√°rio {#443-dax-intermedi√°rio}


**Criar:** Arrastar campo de uma tabela para outra.

**Cardinalidade:**
| Tipo | Significado |
|------|-------------|
| 1:N | Um registro da dimens√£o para N da fato (padr√£o) |
| N:N | Evitar quando poss√≠vel |

#### Tabelas De-Para (Lookup)

Traduz c√≥digos para descri√ß√µes ou agrupa categorias.

**Exemplo:** `depara_categoria`
| cod_produto | categoria |
|-------------|-----------|
| 001-100 | Carnes |
| 101-200 | Frios |
| 201-300 | Embutidos |

---

### DAX Intermedi√°rio

#### Colunas Calculadas vs Medidas

| Tipo | Calculado | Armazenado | Quando usar |
|------|-----------|------------|-------------|
| **Coluna** | Ao atualizar | Sim (ocupa espa√ßo) | Classifica√ß√µes fixas, lookups |
| **Medida** | Ao exibir | N√£o | Agrega√ß√µes, KPIs |

**Regra:** Prefira medidas sempre que poss√≠vel.

---

#### Fun√ß√µes B√°sicas

```dax
// Agrega√ß√µes
Total Vendas = SUM(fato_vendas[valor])
Media Vendas = AVERAGE(fato_vendas[valor])
Qtd Registros = COUNT(fato_vendas[id])
Qtd Clientes = DISTINCTCOUNT(fato_vendas[id_cliente])
```

---

#### CALCULATE (Mudar Contexto)

Aplica filtros √† agrega√ß√£o.

```dax
// Vendas apenas de 2025
Vendas 2025 = 
CALCULATE(
    SUM(fato_vendas[valor]),
    dim_data[ano] = 2025
)

// Vendas da categoria "Carnes"
Vendas Carnes = 
CALCULATE(
    SUM(fato_vendas[valor]),
    dim_produto[categoria] = "Carnes"
)
```

---

#### RELATED (Buscar de Outra Tabela)

Traz valor de tabela relacionada (dimens√£o ‚Üí fato).

```dax
// Coluna calculada na fato_vendas
Categoria = RELATED(dim_produto[categoria])
```

---

#### SUMMARIZE (Criar Tabela Agregada)

```dax
// Tabela com total por categoria

### 4.4.4. Design de Layouts {#444-design-de-layouts}

SUMMARIZE(
    fato_vendas,
    dim_produto[categoria],
    "Total", SUM(fato_vendas[valor]),
    "Qtd", COUNT(fato_vendas[id])
)
```

---

#### Tabelas Calculadas

```dax
// Tabela de datas (calend√°rio)
Calendario = 
CALENDAR(DATE(2020,1,1), DATE(2030,12,31))

// Tabela de par√¢metros
Metas = 
DATATABLE(
    "Mes", INTEGER,
    "Meta", CURRENCY,
    {
        {1, 100000},
        {2, 120000},
        {3, 110000}
    }
)
```

---

#### Exemplo: % Realizado vs Or√ßado

### 4.4.5. Cria√ß√£o de Visuais {#445-cria√ß√£o-de-visuais}

```dax
// Medidas
Realizado = SUM(fato_lancamentos[valor])

Orcado = SUM(dim_orcamento[valor])

% Variacao = 
DIVIDE(
    [Realizado] - [Orcado],
    [Orcado],
    0
)
```

---

### Design de Layouts

#### Figma para Tela de Fundo

**Por que:** Controle total sobre design, consist√™ncia visual.

**Como:**
1. Criar frame 1920x1080 (ou 1280x720)
2. Definir √°reas: cabe√ßalho, filtros, gr√°ficos
3. Aplicar cores e formas
4. Exportar como PNG

**Aplicar no Power BI:**
1. Formato ‚Üí Tela de fundo da p√°gina
2. Imagem ‚Üí Selecionar arquivo
3. Ajustar transpar√™ncia se necess√°rio

### 4.4.6. Interatividade {#446-interatividade}

#### Princ√≠pios de Design

| Princ√≠pio | Aplica√ß√£o |
|-----------|-----------|
| **Hierarquia** | KPIs principais no topo |
| **Alinhamento** | Visuais alinhados em grade |
| **Proximidade** | Agrupar informa√ß√µes relacionadas |
| **Contraste** | Destaque para n√∫meros importantes |

---

### Cria√ß√£o de Visuais

#### Quando Usar Cada Visual

| Visual | Uso |
|--------|-----|
| **Cart√£o** | KPI √∫nico (total, m√©dia) |
| **Tabela** | Dados detalhados |
| **Matriz** | Dados com hierarquia (drill-down) |
| **Barra** | Comparar categorias |
| **Linha** | Evolu√ß√£o no tempo |
| **Combo** | Duas m√©tricas com escalas diferentes |

#### Tabelas e Matrizes

**Tabela:** Lista simples de registros.

**Matriz:** Linhas e colunas com agrega√ß√£o.
- Permite drill-down (expandir/recolher)

### 4.4.7. Boas Pr√°ticas {#447-boas-pr√°ticas}


---

### Interatividade

#### Segmenta√ß√£o (Slicers)

Filtros visuais para o usu√°rio.

**Tipos:**
- Lista (sele√ß√£o √∫nica/m√∫ltipla)
- Dropdown (economiza espa√ßo)
- Entre (range de datas/valores)

#### Filtros

| N√≠vel | Afeta |
|-------|-------|
| Visual | Apenas o visual selecionado |
| P√°gina | Todos os visuais da p√°gina |
| Relat√≥rio | Todas as p√°ginas |

#### Drill-down

Navegar em hierarquias (ex: Ano ‚Üí M√™s ‚Üí Dia).

1. Criar hierarquia na dimens√£o
2. Adicionar ao visual
3. Usar √≠cones de drill no visual

---

### Boas Pr√°ticas

#### Layouts

- ‚úÖ Fundo neutro (cinza claro, branco)

### 4.4.8. Exemplos Contextualizados {#448-exemplos-contextualizados}

- ‚úÖ KPIs no topo
- ‚úÖ Filtros √† esquerda ou topo
- ‚ùå Cores vibrantes em excesso
- ‚ùå Gr√°ficos 3D

#### Tabelas Auxiliares

| Tabela | Uso |
|--------|-----|
| Calend√°rio | An√°lises temporais, time intelligence |
| De-Para | Categoriza√ß√£o, tradu√ß√£o de c√≥digos |
| Par√¢metros | Metas, configura√ß√µes |

#### Tipagem de Colunas

| Tipo | Usar para |
|------|-----------|
| Texto | C√≥digos, descri√ß√µes |
| N√∫mero inteiro | IDs, quantidades |
| N√∫mero decimal | Valores monet√°rios |
| Data | Datas (n√£o texto!) |

#### Nomenclatura

- Tabelas: `fato_`, `dim_`, `depara_`
- Medidas: Come√ßar com verbo (Total, Qtd, %)
- Colunas: snake_case ou PascalCase (consistente)

#### Performance

- ‚úÖ Usar medidas (n√£o colunas calculadas)
- ‚úÖ Remover colunas n√£o usadas
- ‚úÖ Evitar relacionamentos N:N
- ‚ùå Colunas calculadas com RELATED em tabelas grandes

---

## Exemplos Contextualizados

### Dashboard: Sa√≠das de Estoque

**Modelo:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ depara_categoria‚îÇ     ‚îÇ   dim_produto   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ fato_saidas ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  dim_data   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Medidas:**
```dax
Total Saidas = SUM(fato_saidas[quantidade])

Saidas por Categoria = 
CALCULATE(
    [Total Saidas],
    USERELATIONSHIP(dim_produto[cod_categoria], depara_categoria[cod_categoria])
)

Ranking Categoria = 
RANKX(
    ALL(depara_categoria[categoria]),
    [Total Saidas]
)
```

**Visuais:**
- Cart√µes: Total sa√≠das, Qtd categorias
- Matriz: Categoria ‚Üí Produto (com drill-down)
- Gr√°fico barra: Top 10 categorias
- Slicer: Per√≠odo

---

### Dashboard: Acompanhamento Or√ßament√°rio

**Modelo:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  depara_classe  ‚îÇ     ‚îÇ   dim_conta     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ fato_lancamentos‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ           ‚îÇ           ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ dim_data ‚îÇ ‚îÇdim_depto  ‚îÇ ‚îÇorcamento‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Medidas:**
```dax
Realizado = SUM(fato_lancamentos[valor])

Orcado = SUM(orcamento[valor])

Variacao = [Realizado] - [Orcado]

% Variacao = 
DIVIDE([Variacao], [Orcado], 0)

Status = 
IF(
    [% Variacao] > 0.1, "Acima",
    IF([% Variacao] < -0.1, "Abaixo", "OK")
)
```

**Visuais:**
- Cart√µes: Realizado, Or√ßado, % Varia√ß√£o
- Tabela: Classe | Realizado | Or√ßado | Varia√ß√£o | Status
- Gr√°fico linha: Tend√™ncia mensal (Realizado vs Or√ßado)
- Slicers: Departamento, Per√≠odo, Classe

---

### Ex: Power BI - An√°lise de Vendas (NF-e Sa√≠da 2020-2025)

Sugest√£o de an√°lise utilizando a base hist√≥rica de notas fiscais de sa√≠da.

### Objetivo

Acompanhar a evolu√ß√£o do faturamento ao longo do tempo e identificar padr√µes de sazonalidade que impactam o neg√≥cio.

### O que deve ser constru√≠do no Power BI

1. **Faturamento mensal e anual** - Gr√°fico de linhas mostrando evolu√ß√£o temporal
2. **Comparativo ano a ano** - Faturamento por ano para identificar crescimento/queda
3. **An√°lise de sazonalidade** - Identificar meses de pico e baixa nas vendas
4. **Top 10 produtos** - Quais produtos mais faturam (curva ABC simples)
5. **Volume de notas emitidas** - Quantidade de NF-e por m√™s (indicador operacional)

### Visualiza√ß√µes Sugeridas

- Gr√°fico de linha para evolu√ß√£o mensal
- Gr√°fico de barras para comparativo anual
- Tabela com top produtos por faturamento

### Valor da An√°lise

Vis√£o r√°pida e clara do desempenho comercial, identifica√ß√£o de tend√™ncias e padr√µes sazonais para planejamento.

| Complexidade | Execu√ß√£o | Valor Informacional |
|--------------|----------|---------------------|
| Baixa | R√°pida | Alto |

---


---

# 5. Qualidade e Valida√ß√£o

## 5.1. Valida√ß√£o Cruzada

### 5.1.1. Import√¢ncia {#511-import√¢ncia}

A valida√ß√£o cruzada √© essencial para garantir a integridade e confiabilidade dos dados transformados.

### 5.1.2. Princ√≠pios {#512-princ√≠pios}

- Comparar totais entre origem e destino
- Validar cardinalidades e relacionamentos
- Verificar consist√™ncia de agrega√ß√µes

### 5.1.3. Recomenda√ß√£o {#513-recomenda√ß√£o}

Realizar valida√ß√£o tripla: Origem (SQL Server) ‚Üí Transforma√ß√£o (dbt) ‚Üí Destino (Redshift/Power BI)


---

# 6. Pr√°tica

## 6.1. Exerc√≠cios SQL Anal√≠ticos


Exerc√≠cios propostos para desenvolver habilidade essencial de An√°lise de Dados: realizar consultas SQL anal√≠ticas que permitam responder perguntas de neg√≥cio de forma eficiente e precisa.

### Estrutura dos Exerc√≠cios

| Bloco | Exerc√≠cios | Conceito | N√≠vel |
|-------|------------|----------|-------|
| 1 | EX1-5 | SELECT + WHERE | ‚≠ê |
| 2 | EX6-10 | JOINs | ‚≠ê‚≠ê |
| 3 | EX11-15 | Agrega√ß√µes | ‚≠ê‚≠ê |
| 4 | EX16-20 | CTEs | ‚≠ê‚≠ê‚≠ê |
| 5 | EX21-25 | Window Functions | ‚≠ê‚≠ê‚≠ê |
| 6 | EX26-30 | UNION + Subconsultas + DML | ‚≠ê‚≠ê‚≠ê |

### Tabelas Principais

`E440NFC`, `E440IPC`, `E095FOR`, `E440ISC`, `E660INC`, `E075PRO`, `E070FIL`

### Aplica√ß√µes

Cont√°bil | Fiscal | Compras | Financeiro | Controladoria

---

### Bloco 1: B√°sico (SELECT + WHERE) ‚≠ê

#### EX1: Consulta de Lan√ßamentos Cont√°beis com Filtro por Conta Espec√≠fica

**Objetivo:** Extrair lan√ßamentos cont√°beis da tabela E640LCT

**Retornar:** C√≥digo Empresa, C√≥digo Filial, N√∫mero Lan√ßamento, Data Lan√ßamento, Conta D√©bito, Conta Cr√©dito, Valor Lan√ßamento e Complemento de Lan√ßamento.

**Crit√©rios:** Ano de 2025 e lan√ßamentos que envolvam a Conta 11730.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    CodEmp AS empresa,
    CodFil AS filial,
    NumLct AS numero_lancamento,
    DatLct AS data_lancamento,
    CtaDeb AS conta_debito,
    CtaCre AS conta_credito,
    VlrLct AS valor_lancamento,
    CplLct AS complemento
FROM E640LCT
WHERE DatLct BETWEEN '20250101' AND '20251231'
    AND (CtaDeb = 11730 OR CtaCre = 11730)
```

</details>

---

#### EX2: An√°lise de Itens de Produto em Notas Fiscais de Entrada

**Objetivo:** Consultar itens de produto da tabela E440IPC (Compras - Itens de Produto)

**Retornar:** C√≥digo Empresa, C√≥digo Filial, N√∫mero da NF, C√≥digo do Fornecedor, C√≥digo do Produto, Quantidade Recebida, Pre√ßo Unit√°rio, Valor L√≠quido e Data de Gera√ß√£o.

**Crit√©rios:** Primeiro semestre de 2025 (Janeiro a Junho) com quantidade superior a 10 unidades.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    CodEmp AS empresa,
    CodFil AS filial,
    NumNfc AS numero_nota,
    CodFor AS codigo_fornecedor,
    CodPro AS codigo_produto,
    QtdRec AS quantidade_recebida,
    PreUni AS preco_unitario,
    VlrLiq AS valor_liquido,
    DatGer AS data_geracao
FROM E440IPC
WHERE DatGer BETWEEN '20250101' AND '20250630'
    AND QtdRec > 10
```

</details>

---

#### EX3: Relat√≥rio de Servi√ßos com Impostos Retidos

**Objetivo:** Extrair itens de servi√ßo da tabela E440ISC (Compras - Itens de Servi√ßo)

**Retornar:** C√≥digo Empresa, C√≥digo Filial, N√∫mero da NF, C√≥digo do Fornecedor, C√≥digo do Servi√ßo, Valor Bruto, Valor de ISS, Valor de IRRF e Data de Gera√ß√£o.

**Crit√©rios:** M√™s de Mar√ßo de 2025, ordenado por valor bruto decrescente.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    CodEmp AS empresa,
    CodFil AS filial,
    NumNfc AS numero_nota,
    CodFor AS codigo_fornecedor,
    CodSer AS codigo_servico,
    VlrBru AS valor_bruto,
    VlrIss AS valor_iss,
    VlrIrf AS valor_irrf,
    DatGer AS data_geracao
FROM E440ISC
WHERE DatGer BETWEEN '20250301' AND '20250331'
ORDER BY VlrBru DESC
```

</details>

---

#### EX4: Levantamento de Notas Fiscais Fechadas com Tributos

**Objetivo:** Consultar dados gerais de notas fiscais na tabela E440NFC (Compras - Dados Gerais)

**Retornar:** C√≥digo Empresa, C√≥digo Filial, N√∫mero da NF, C√≥digo do Fornecedor, Data de Emiss√£o, Data de Entrada, Valor de Produtos, Valor de ICMS, Valor de IPI e Situa√ß√£o da NF.

**Crit√©rios:** Segundo trimestre de 2025 (Abril a Junho) e status 'F' (Fechada).

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    CodEmp AS empresa,
    CodFil AS filial,
    NumNfc AS numero_nota,
    CodFor AS codigo_fornecedor,
    DatEmi AS data_emissao,
    DatEnt AS data_entrada,
    VlrBpr AS valor_produtos,
    VlrIcm AS valor_icms,
    VlrIpi AS valor_ipi,
    SitNfc AS situacao_nota
FROM E440NFC
WHERE DatEnt BETWEEN '20250401' AND '20250630'
    AND SitNfc = 'F'
```

</details>

---

#### EX5: Apura√ß√£o Fiscal de Itens com Valor Relevante

**Objetivo:** Analisar itens fiscais da tabela E660INC (Impostos - Itens de Produto/Servi√ßo)

**Retornar:** C√≥digo Filial, C√≥digo do Fornecedor, N√∫mero da NF, C√≥digo do Produto, Quantidade de Entrada, Valor Cont√°bil, Valor de ICMS, Percentual de ICMS e Data de Gera√ß√£o.

**Crit√©rios:** Primeira quinzena de Janeiro de 2025 (01/01 a 15/01) com valor cont√°bil superior a R$ 500,00.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    CodFil AS filial,
    CodFor AS codigo_fornecedor,
    NumNfi AS numero_nota,
    CodPro AS codigo_produto,
    QtdEnt AS quantidade_entrada,
    VlrCtb AS valor_contabil,
    VlrIcm AS valor_icms,
    PerIcm AS percentual_icms,
    DatGer AS data_geracao
FROM E660INC
WHERE DatGer BETWEEN '20250101' AND '20250115'
    AND VlrCtb > 500
```

</details>

---

### Bloco 2: JOINs ‚≠ê‚≠ê

#### EX6: An√°lise Completa de Compras com Dados de Fornecedores

**Objetivo:** Consultar notas fiscais de entrada relacionando com dados cadastrais de fornecedores

**Retornar:** C√≥digo Empresa, C√≥digo Filial, N√∫mero NF, Nome do Fornecedor, CNPJ, Cidade, Data de Emiss√£o, Valor Total, Status da NF.

**Crit√©rios:** Primeiro trimestre de 2025 (Janeiro a Mar√ßo), ordenado por valor decrescente.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    nfc.CodEmp AS codigo_empresa,
    nfc.CodFil AS codigo_filial,
    nfc.NumNfc AS numero_nf,
    fornec.NomFor AS nome_fornecedor,
    fornec.CgcCpf AS cnpj_fornecedor,
    fornec.CidFor AS cidade_fornecedor,
    nfc.DatEmi AS data_emissao,
    nfc.VlrLiq AS valor_total,
    nfc.SitNfc AS status_nf
FROM E440NFC AS nfc
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
WHERE nfc.DatEmi BETWEEN '20250101' AND '20250331'
ORDER BY nfc.VlrLiq DESC
```

</details>

---

#### EX7: Itens de Produto com Informa√ß√µes Detalhadas de Produto e Fornecedor

**Objetivo:** Analisar itens de compra relacionando produtos, fornecedores e notas fiscais

**Retornar:** N√∫mero NF, Nome Fornecedor, C√≥digo Produto, Descri√ß√£o Produto, Quantidade Recebida, Pre√ßo Unit√°rio, Valor Total do Item, Data de Entrada.

**Crit√©rios:** M√™s de Fevereiro 2025, produtos com valor total superior a R$ 1.000,00.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    ipc.NumNfc AS numero_nf,
    fornec.NomFor AS nome_fornecedor,
    ipc.CodPro AS codigo_produto,
    prod.DesPro AS descricao_produto,
    ipc.QtdRec AS quantidade_recebida,
    ipc.PreUni AS preco_unitario,
    (ipc.QtdRec * ipc.PreUni) AS valor_total_item,
    nfc.DatEnt AS data_entrada
FROM E440IPC AS ipc
    INNER JOIN E440NFC AS nfc
        ON ipc.CodEmp = nfc.CodEmp
        AND ipc.CodFil = nfc.CodFil
        AND ipc.NumNfc = nfc.NumNfc
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
    INNER JOIN E075PRO AS prod
        ON ipc.CodPro = prod.CodPro
WHERE nfc.DatGer BETWEEN '20250201' AND '20250228'
    AND (ipc.QtdRec * ipc.PreUni) > 1000
ORDER BY valor_total_item DESC
```

</details>

---

#### EX8: Consolida√ß√£o de Impostos com Filiais e Fornecedores

**Objetivo:** Relacionar dados fiscais de entrada com informa√ß√µes organizacionais

**Retornar:** Nome Filial, Nome Fornecedor, N√∫mero NF, Data Emiss√£o, Valor Base ICMS, Valor ICMS, Valor IPI, Valor Total Tributos.

**Crit√©rios:** Segundo trimestre de 2025 (Abril a Junho), agrupado por filial.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    fil.NomFil AS nome_filial,
    fornec.NomFor AS nome_fornecedor,
    nfc.NumNfi AS numero_nf,
    nfc.DatEmi AS data_emissao,
    inc.VlrBic AS base_icms,
    inc.VlrIcm AS valor_icms,
    inc.VlrIpi AS valor_ipi,
    (ISNULL(inc.VlrIcm, 0) + ISNULL(inc.VlrIpi, 0) +
     ISNULL(inc.VlrPir, 0) + ISNULL(inc.VlrCor, 0)) AS total_tributos
FROM E660INC AS inc
    INNER JOIN E660NFC AS nfc
        ON inc.CodFil = nfc.CodFil
        AND inc.CodFor = nfc.CodFor
        AND inc.NumNfi = nfc.NumNfi
    INNER JOIN E070FIL AS fil
        ON nfc.CodFil = fil.CodFil
        AND nfc.CodEmp = fil.CodEmp
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
WHERE nfc.DatGer BETWEEN '20250401' AND '20250630'
ORDER BY fil.NomFil, total_tributos DESC
```

</details>

---

#### EX9: An√°lise de Servi√ßos com Centro de Custo e Fornecedor

**Objetivo:** Relacionar servi√ßos contratados com centros de custo e fornecedores

**Retornar:** Nome Fornecedor, Descri√ß√£o Servi√ßo, Centro de Custo, Descri√ß√£o Centro Custo, Quantidade, Valor Unit√°rio, Valor Total, Valor ISS Retido, Data Gera√ß√£o.

**Crit√©rios:** Janeiro a Mar√ßo 2025, apenas servi√ßos com ISS retido, ordenado por centro de custo.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    fornec.NomFor AS nome_fornecedor,
    serv.DesSer AS descricao_servico,
    isc.CodCcu AS centro_custo,
    ccu.DesCcu AS descricao_centro_custo,
    isc.QtdRec AS quantidade,
    isc.PreUni AS valor_unitario,
    isc.VlrLiq AS valor_liquido,
    isc.VlrIss AS valor_iss,
    nfc.DatGer AS data_geracao
FROM E440ISC AS isc
    INNER JOIN E440NFC AS nfc
        ON isc.CodEmp = nfc.CodEmp
        AND isc.CodFil = nfc.CodFil
        AND isc.NumNfc = nfc.NumNfc
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
    LEFT JOIN E080SER AS serv
        ON isc.CodSer = serv.CodSer
    LEFT JOIN E044CCU AS ccu
        ON isc.CodCcu = ccu.CodCcu
        AND isc.CodEmp = ccu.CodEmp
WHERE nfc.DatGer BETWEEN '20250101' AND '20250331'
    AND isc.VlrIss > 0
ORDER BY ccu.DesCcu, isc.VlrLiq DESC
```

</details>

---

#### EX10: Rastreamento Completo: Compra, Contabiliza√ß√£o e Impostos

**Objetivo:** Relacionar compras com lan√ßamentos cont√°beis e apura√ß√£o fiscal em uma vis√£o integrada

**Retornar:** N√∫mero NF, Nome Fornecedor, Descri√ß√£o Produto, Conta Cont√°bil D√©bito, Descri√ß√£o Conta, Valor Cont√°bil, Base ICMS, Valor ICMS, Data Lan√ßamento.

**Crit√©rios:** Fevereiro 2025, apenas itens com lan√ßamento cont√°bil e ICMS destacado.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT DISTINCT
    ipc.NumNfc AS numero_nf,
    fornec.NomFor AS nome_fornecedor,
    prod.DesPro AS descricao_produto,
    lct.CtaDeb AS conta_debito,
    pla.DesCta AS descricao_conta,
    inc.VlrCtb AS valor_contabil,
    inc.VlrBic AS base_icms,
    inc.VlrIcm AS valor_icms,
    lct.DatLct AS data_lancamento
FROM E440IPC AS ipc
    INNER JOIN E440NFC AS nfc
        ON ipc.CodEmp = nfc.CodEmp
        AND ipc.CodFil = nfc.CodFil
        AND ipc.NumNfc = nfc.NumNfc
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
    INNER JOIN E075PRO AS prod
        ON ipc.CodPro = prod.CodPro
    LEFT JOIN E660INC AS inc
        ON ipc.CodEmp = inc.CodEmp
        AND ipc.CodFil = inc.CodFil
        AND ipc.NumNfc = inc.NumNfi
        AND ipc.SeqIpc = inc.SeqIpc
    LEFT JOIN E640LCT AS lct
        ON nfc.CodEmp = lct.CodEmp
        AND nfc.CodFil = lct.CodFil
        AND nfc.DatEmi = lct.DatLct
    LEFT JOIN E045PLA AS pla
        ON lct.CtaDeb = pla.CtaRed
        AND lct.CodEmp = pla.CodEmp
WHERE nfc.DatGer BETWEEN '20250201' AND '20250228'
    AND inc.VlrIcm > 0
    AND lct.NumLct IS NOT NULL
ORDER BY nfc.DatEmi, ipc.NumNfc
```

</details>

---

### Bloco 3: Agrega√ß√µes ‚≠ê‚≠ê

#### EX11: Totaliza√ß√£o de Compras por Fornecedor no Trimestre

**Objetivo:** Agregar valores de compras por fornecedor para an√°lise de volume de aquisi√ß√µes

**Retornar:** C√≥digo Fornecedor, Nome Fornecedor, Quantidade de Notas Fiscais, Valor Total de Compras, Valor M√©dio por Nota, Valor Total de ICMS.

**Crit√©rios:** Primeiro trimestre de 2025, agrupar por fornecedor, ordenar por valor total decrescente.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    fornec.CodFor AS codigo_fornecedor,
    fornec.NomFor AS nome_fornecedor,
    COUNT(DISTINCT nfc.NumNfc) AS quantidade_notas,
    SUM(nfc.VlrLiq) AS valor_total_compras,
    AVG(nfc.VlrLiq) AS valor_medio_nota,
    SUM(nfc.VlrIcm) AS valor_total_icms
FROM E440NFC AS nfc
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
WHERE nfc.DatEnt BETWEEN '20250101' AND '20250331'
GROUP BY fornec.CodFor, fornec.NomFor
ORDER BY valor_total_compras DESC
```

</details>

---

#### EX12: An√°lise Mensal de Impostos Recuper√°veis por Filial

**Objetivo:** Consolidar valores de cr√©ditos tribut√°rios (PIS e COFINS) por filial e m√™s

**Retornar:** C√≥digo Filial, Nome Filial, M√™s/Ano, Quantidade de Itens, Total Base PIS, Total PIS Recuper√°vel, Total Base COFINS, Total COFINS Recuper√°vel.

**Crit√©rios:** Primeiro semestre de 2025, agrupar por filial e m√™s, apenas itens com cr√©dito.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    fil.CodFil AS codigo_filial,
    fil.NomFil AS nome_filial,
    MONTH(inc.DatGer) AS mes,
    YEAR(inc.DatGer) AS ano,
    COUNT(*) AS quantidade_itens,
    SUM(inc.VlrBpr) AS total_base_pis,
    SUM(inc.VlrPir) AS total_pis_recuperavel,
    SUM(inc.VlrBcr) AS total_base_cofins,
    SUM(inc.VlrCor) AS total_cofins_recuperavel
FROM E660INC AS inc
    INNER JOIN E070FIL AS fil
        ON inc.CodFil = fil.CodFil
        AND inc.CodEmp = fil.CodEmp
WHERE inc.DatGer BETWEEN '20250101' AND '20250630'
    AND (inc.VlrPir > 0 OR inc.VlrCor > 0)
GROUP BY fil.CodFil, fil.NomFil, MONTH(inc.DatGer), YEAR(inc.DatGer)
ORDER BY fil.CodFil, ano, mes
```

</details>

---

#### EX13: Ranking de Produtos Mais Comprados com An√°lise de Pre√ßo

**Objetivo:** Identificar os produtos com maior volume de compras e varia√ß√£o de pre√ßos

**Retornar:** C√≥digo Produto, Descri√ß√£o Produto, Quantidade Total Comprada, Quantidade de Fornecedores, Pre√ßo M√≠nimo, Pre√ßo M√°ximo, Pre√ßo M√©dio, Valor Total Gasto.

**Crit√©rios:** Ano de 2025, agrupar por produto, mostrar apenas produtos com mais de 5 compras.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    prod.CodPro AS codigo_produto,
    prod.DesPro AS descricao_produto,
    SUM(ipc.QtdRec) AS quantidade_total_comprada,
    COUNT(DISTINCT nfc.CodFor) AS quantidade_fornecedores,
    MIN(ipc.PreUni) AS preco_minimo,
    MAX(ipc.PreUni) AS preco_maximo,
    AVG(ipc.PreUni) AS preco_medio,
    SUM(ipc.VlrLiq) AS valor_total_gasto
FROM E440IPC AS ipc
    INNER JOIN E440NFC AS nfc
        ON ipc.CodEmp = nfc.CodEmp
        AND ipc.CodFil = nfc.CodFil
        AND ipc.NumNfc = nfc.NumNfc
    INNER JOIN E075PRO AS prod
        ON ipc.CodPro = prod.CodPro
WHERE nfc.DatGer BETWEEN '20250101' AND '20251231'
GROUP BY prod.CodPro, prod.DesPro
HAVING COUNT(*) > 5
ORDER BY quantidade_total_comprada DESC
```

</details>

---

#### EX14: Consolida√ß√£o de Servi√ßos por Centro de Custo com An√°lise Fiscal

**Objetivo:** Sumarizar gastos com servi√ßos por centro de custo incluindo reten√ß√µes tribut√°rias

**Retornar:** Centro de Custo, Descri√ß√£o Centro Custo, Quantidade de Notas, Valor Total Servi√ßos, Total ISS Retido, Total IRRF Retido, Total PIS Retido, Total COFINS Retido.

**Crit√©rios:** Primeiro semestre de 2025, agrupar por centro de custo, ordenar por valor total.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    ccu.CodCcu AS centro_custo,
    ccu.DesCcu AS descricao_centro_custo,
    COUNT(DISTINCT isc.NumNfc) AS quantidade_notas,
    SUM(isc.VlrLiq) AS valor_total_servicos,
    SUM(isc.VlrIss) AS total_iss_retido,
    SUM(isc.VlrIrf) AS total_irrf_retido,
    SUM(isc.VlrPit) AS total_pis_retido,
    SUM(isc.VlrCrt) AS total_cofins_retido
FROM E440ISC AS isc
    INNER JOIN E440NFC AS nfc
        ON isc.CodEmp = nfc.CodEmp
        AND isc.CodFil = nfc.CodFil
        AND isc.NumNfc = nfc.NumNfc
    LEFT JOIN E044CCU AS ccu
        ON isc.CodCcu = ccu.CodCcu
        AND isc.CodEmp = ccu.CodEmp
WHERE nfc.DatGer BETWEEN '20250101' AND '20250630'
GROUP BY ccu.CodCcu, ccu.DesCcu
ORDER BY valor_total_servicos DESC
```

</details>

---

#### EX15: An√°lise Comparativa de Compras: Produtos vs Servi√ßos por Filial

**Objetivo:** Comparar volumes de compras de produtos e servi√ßos por filial em uma √∫nica vis√£o

**Retornar:** C√≥digo Filial, Nome Filial, Quantidade NF Produtos, Valor Total Produtos, Quantidade NF Servi√ßos, Valor Total Servi√ßos, Valor Total Geral, Percentual Produtos.

**Crit√©rios:** Segundo trimestre de 2025, agrupar por filial, calcular participa√ß√£o percentual.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    fil.CodFil AS codigo_filial,
    fil.NomFil AS nome_filial,
    COUNT(DISTINCT CASE WHEN nfc.TipNfe = 'P' THEN nfc.NumNfc END) AS qtd_nf_produtos,
    SUM(CASE WHEN nfc.TipNfe = 'P' THEN nfc.VlrBpr ELSE 0 END) AS valor_total_produtos,
    COUNT(DISTINCT CASE WHEN nfc.TipNfe = 'S' THEN nfc.NumNfc END) AS qtd_nf_servicos,
    SUM(CASE WHEN nfc.TipNfe = 'S' THEN nfc.VlrBse ELSE 0 END) AS valor_total_servicos,
    SUM(nfc.VlrLiq) AS valor_total_geral,
    CASE 
        WHEN SUM(nfc.VlrLiq) > 0 
        THEN ROUND((SUM(CASE WHEN nfc.TipNfe = 'P' THEN nfc.VlrBpr ELSE 0 END) / SUM(nfc.VlrLiq)) * 100, 2)
        ELSE 0 
    END AS percentual_produtos
FROM E440NFC AS nfc
    INNER JOIN E070FIL AS fil
        ON nfc.CodFil = fil.CodFil
        AND nfc.CodEmp = fil.CodEmp
WHERE nfc.DatEnt BETWEEN '20250401' AND '20250630'
GROUP BY fil.CodFil, fil.NomFil
ORDER BY valor_total_geral DESC
```

</details>

---

### Bloco 4: CTEs ‚≠ê‚≠ê‚≠ê

#### EX16: CTE B√°sica - Totaliza√ß√£o de Compras por Fornecedor com Filtro

**Objetivo:** Utilizar CTE para pr√©-calcular totais de compras e depois filtrar fornecedores relevantes

**Retornar:** C√≥digo Fornecedor, Nome Fornecedor, Quantidade de Notas, Valor Total de Compras, Ticket M√©dio, classificando apenas fornecedores com mais de 3 notas.

**Crit√©rios:** Primeiro trimestre de 2025, valor total acima de R$ 10.000,00.

<details>
<summary>üìù Ver Resposta</summary>

```sql
WITH TotaisCompras AS (
    SELECT
        fornec.CodFor AS codigo_fornecedor,
        fornec.NomFor AS nome_fornecedor,
        COUNT(DISTINCT nfc.NumNfc) AS quantidade_notas,
        SUM(nfc.VlrLiq) AS valor_total_compras,
        AVG(nfc.VlrLiq) AS ticket_medio
    FROM E440NFC AS nfc
        INNER JOIN E095FOR AS fornec
            ON nfc.CodFor = fornec.CodFor
    WHERE nfc.DatEnt BETWEEN '20250101' AND '20250331'
    GROUP BY fornec.CodFor, fornec.NomFor
)
SELECT
    codigo_fornecedor,
    nome_fornecedor,
    quantidade_notas,
    valor_total_compras,
    ticket_medio
FROM TotaisCompras
WHERE quantidade_notas > 3
    AND valor_total_compras > 10000
ORDER BY valor_total_compras DESC
```

</details>

---

#### EX17: CTEs Encadeadas - An√°lise de Produtos com C√°lculo de Participa√ß√£o

**Objetivo:** Usar m√∫ltiplas CTEs para calcular totais gerais e depois percentual de participa√ß√£o

**Retornar:** C√≥digo Produto, Descri√ß√£o Produto, Quantidade Comprada, Valor Total, Percentual sobre Total Geral, Classifica√ß√£o (A/B/C conforme participa√ß√£o).

**Crit√©rios:** Primeiro semestre de 2025, ordenar por valor decrescente.

<details>
<summary>üìù Ver Resposta</summary>

```sql
WITH ComprasProdutos AS (
    SELECT
        prod.CodPro AS codigo_produto,
        prod.DesPro AS descricao_produto,
        SUM(ipc.QtdRec) AS quantidade_comprada,
        SUM(ipc.VlrLiq) AS valor_total
    FROM E440IPC AS ipc
        INNER JOIN E440NFC AS nfc
            ON ipc.CodEmp = nfc.CodEmp
            AND ipc.CodFil = nfc.CodFil
            AND ipc.NumNfc = nfc.NumNfc
        INNER JOIN E075PRO AS prod
            ON ipc.CodPro = prod.CodPro
    WHERE nfc.DatGer BETWEEN '20250101' AND '20250630'
    GROUP BY prod.CodPro, prod.DesPro
),
TotalGeral AS (
    SELECT SUM(valor_total) AS total_geral
    FROM ComprasProdutos
)
SELECT
    cp.codigo_produto,
    cp.descricao_produto,
    cp.quantidade_comprada,
    cp.valor_total,
    ROUND((cp.valor_total / tg.total_geral) * 100, 2) AS percentual_participacao,
    CASE
        WHEN (cp.valor_total / tg.total_geral) * 100 >= 10 THEN 'A'
        WHEN (cp.valor_total / tg.total_geral) * 100 >= 5 THEN 'B'
        ELSE 'C'
    END AS classificacao_abc
FROM ComprasProdutos cp
    CROSS JOIN TotalGeral tg
ORDER BY cp.valor_total DESC
```

</details>

---

#### EX18: CTE com Agrega√ß√£o Temporal - Comparativo Mensal de Impostos

**Objetivo:** Criar CTE para agregar impostos por m√™s e depois calcular varia√ß√µes

**Retornar:** M√™s, Ano, Total Base ICMS, Total ICMS, Total IPI, Total PIS, Total COFINS, Carga Tribut√°ria Efetiva (%).

**Crit√©rios:** Primeiro semestre de 2025, agrupar por m√™s.

<details>
<summary>üìù Ver Resposta</summary>

```sql
WITH ImpostosMensais AS (
    SELECT
        MONTH(nfc.DatEmi) AS mes,
        YEAR(nfc.DatEmi) AS ano,
        SUM(inc.VlrBic) AS total_base_icms,
        SUM(inc.VlrIcm) AS total_icms,
        SUM(inc.VlrIpi) AS total_ipi,
        SUM(inc.VlrPir) AS total_pis,
        SUM(inc.VlrCor) AS total_cofins,
        SUM(inc.VlrCtb) AS total_valor_contabil
    FROM E660INC AS inc
        INNER JOIN E660NFC AS nfc
            ON inc.CodFil = nfc.CodFil
            AND inc.CodFor = nfc.CodFor
            AND inc.NumNfi = nfc.NumNfi
    WHERE nfc.DatEmi BETWEEN '20250101' AND '20250630'
    GROUP BY MONTH(nfc.DatEmi), YEAR(nfc.DatEmi)
)
SELECT
    mes,
    ano,
    total_base_icms,
    total_icms,
    total_ipi,
    total_pis,
    total_cofins,
    (total_icms + total_ipi + total_pis + total_cofins) AS total_impostos,
    CASE
        WHEN total_valor_contabil > 0 
        THEN ROUND(((total_icms + total_ipi + total_pis + total_cofins) / total_valor_contabil) * 100, 2)
        ELSE 0
    END AS carga_tributaria_percentual
FROM ImpostosMensais
ORDER BY ano, mes
```

</details>

---

#### EX19: CTEs M√∫ltiplas com JOINs - An√°lise Integrada de Performance por Filial

**Objetivo:** Combinar CTEs de produtos e servi√ßos para vis√£o consolidada por filial

**Retornar:** C√≥digo Filial, Nome Filial, Qtd NF Produtos, Valor Produtos, Qtd NF Servi√ßos, Valor Servi√ßos, Valor Total, Maior Fornecedor (nome), Valor Maior Fornecedor.

**Crit√©rios:** Segundo trimestre de 2025.

---

#### EX20: CTE Complexa - An√°lise de Varia√ß√£o M√™s a M√™s com M√∫ltiplas Dimens√µes

**Objetivo:** Usar CTEs para calcular totais mensais e depois comparar com m√™s anterior

**Retornar:** M√™s Atual, Ano, Valor Compras M√™s Atual, Valor M√™s Anterior, Varia√ß√£o Absoluta, Varia√ß√£o Percentual, Quantidade Fornecedores Ativos, Ticket M√©dio.

**Crit√©rios:** Primeiro semestre de 2025, incluir an√°lise comparativa.

<details>
<summary>üìù Ver Resposta</summary>

```sql
WITH ComprasMensais AS (
    SELECT
        MONTH(nfc.DatEnt) AS mes,
        YEAR(nfc.DatEnt) AS ano,
        SUM(nfc.VlrLiq) AS valor_compras,
        COUNT(DISTINCT nfc.NumNfc) AS qtd_notas,
        COUNT(DISTINCT nfc.CodFor) AS qtd_fornecedores
    FROM E440NFC AS nfc
    WHERE nfc.DatEnt BETWEEN '20250101' AND '20250630'
        AND nfc.SitNfc = 'F'
    GROUP BY MONTH(nfc.DatEnt), YEAR(nfc.DatEnt)
),
ComparacaoMensal AS (
    SELECT
        cm.mes,
        cm.ano,
        cm.valor_compras,
        cm.qtd_notas,
        cm.qtd_fornecedores,
        LAG(cm.valor_compras) OVER (ORDER BY cm.ano, cm.mes) AS valor_mes_anterior,
        cm.valor_compras / NULLIF(cm.qtd_notas, 0) AS ticket_medio
    FROM ComprasMensais cm
)
SELECT
    mes,
    ano,
    valor_compras,
    valor_mes_anterior,
    (valor_compras - ISNULL(valor_mes_anterior, 0)) AS variacao_absoluta,
    CASE
        WHEN valor_mes_anterior > 0 
        THEN ROUND(((valor_compras - valor_mes_anterior) / valor_mes_anterior) * 100, 2)
        ELSE NULL
    END AS variacao_percentual,
    qtd_fornecedores AS fornecedores_ativos,
    ROUND(ticket_medio, 2) AS ticket_medio
FROM ComparacaoMensal
ORDER BY ano, mes
```

</details>

---

### Bloco 5: Window Functions ‚≠ê‚≠ê‚≠ê

#### EX21: Window Function B√°sica - Numera√ß√£o Sequencial de Notas por Fornecedor

**Objetivo:** Adicionar numera√ß√£o sequencial √†s notas fiscais de cada fornecedor

**Retornar:** C√≥digo Fornecedor, Nome Fornecedor, N√∫mero NF, Data Entrada, Valor da Nota, N√∫mero Sequencial (particionado por fornecedor).

**Crit√©rios:** Primeiro trimestre de 2025, ordenar por data de entrada.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    fornec.CodFor AS codigo_fornecedor,
    fornec.NomFor AS nome_fornecedor,
    nfc.NumNfc AS numero_nf,
    nfc.DatEnt AS data_entrada,
    nfc.VlrLiq AS valor_nota,
    ROW_NUMBER() OVER (PARTITION BY fornec.CodFor ORDER BY nfc.DatEnt) AS numero_sequencial
FROM E440NFC AS nfc
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
WHERE nfc.DatEnt BETWEEN '20250101' AND '20250331'
ORDER BY fornec.CodFor, nfc.DatEnt
```

</details>

---

#### EX22: Ranking Simples - Top Fornecedores por Valor Total

**Objetivo:** Criar ranking de fornecedores baseado no valor total de compras

**Retornar:** Posi√ß√£o no Ranking, C√≥digo Fornecedor, Nome Fornecedor, Valor Total de Compras, Quantidade de Notas.

**Crit√©rios:** Primeiro semestre de 2025, ordenar por valor decrescente.

<details>
<summary>üìù Ver Resposta</summary>

```sql
SELECT
    RANK() OVER (ORDER BY SUM(nfc.VlrLiq) DESC) AS posicao_ranking,
    fornec.CodFor AS codigo_fornecedor,
    fornec.NomFor AS nome_fornecedor,
    SUM(nfc.VlrLiq) AS valor_total_compras,
    COUNT(nfc.NumNfc) AS quantidade_notas
FROM E440NFC AS nfc
    INNER JOIN E095FOR AS fornec
        ON nfc.CodFor = fornec.CodFor
WHERE nfc.DatEnt BETWEEN '20250101' AND '20250630'
GROUP BY fornec.CodFor, fornec.NomFor
ORDER BY posicao_ranking
```

</details>

---

#### EX23: PARTITION BY B√°sico - Ranking de Produtos Mais Comprados por Filial

**Objetivo:** Classificar os produtos mais comprados dentro de cada filial

**Retornar:** C√≥digo Filial, Nome Filial, C√≥digo Produto, Descri√ß√£o Produto, Quantidade Total, Ranking dentro da Filial.

**Crit√©rios:** Primeiro trimestre de 2025, mostrar apenas top 3 por filial.

<details>
<summary>üìù Ver Resposta</summary>

```sql
WITH ProdutosPorFilial AS (
    SELECT
        fil.CodFil AS codigo_filial,
        fil.NomFil AS nome_filial,
        prod.CodPro AS codigo_produto,
        prod.DesPro AS descricao_produto,
        SUM(ipc.QtdRec) AS quantidade_total,
        RANK() OVER (PARTITION BY fil.CodFil ORDER BY SUM(ipc.QtdRec) DESC) AS ranking_filial
    FROM E440IPC AS ipc
        INNER JOIN E440NFC AS nfc
            ON ipc.CodEmp = nfc.CodEmp
            AND ipc.CodFil = nfc.CodFil
            AND ipc.NumNfc = nfc.NumNfc
        INNER JOIN E070FIL AS fil
            ON nfc.CodFil = fil.CodFil
            AND nfc.CodEmp = fil.CodEmp
        INNER JOIN E075PRO AS prod
            ON ipc.CodPro = prod.CodPro
    WHERE nfc.DatGer BETWEEN '20250101' AND '20250331'
    GROUP BY fil.CodFil, fil.NomFil, prod.CodPro, prod.DesPro
)
SELECT
    codigo_filial,
    nome_filial,
    ranking_filial,
    codigo_produto,
    descricao_produto,
    quantidade_total
FROM ProdutosPorFilial
WHERE ranking_filial <= 3
ORDER BY codigo_filial, ranking_filial
```

</details>

---

#### EX24: Fun√ß√µes LAG e LEAD - Compara√ß√£o com M√™s Anterior e Posterior

**Objetivo:** Calcular valor mensal de compras e comparar com meses adjacentes

**Retornar:** M√™s, Ano, Valor do M√™s, Valor M√™s Anterior, Valor M√™s Seguinte, Varia√ß√£o vs M√™s Anterior (valor absoluto).

**Crit√©rios:** Primeiro semestre de 2025.

<details>
<summary>üìù Ver Resposta</summary>

```sql
WITH ComprasMensais AS (
    SELECT
        MONTH(nfc.DatEnt) AS mes,
        YEAR(nfc.DatEnt) AS ano,
        SUM(nfc.VlrLiq) AS valor_mes
    FROM E440NFC AS nfc
    WHERE nfc.DatEnt BETWEEN '20250101' AND '20250630'
    GROUP BY MONTH(nfc.DatEnt), YEAR(nfc.DatEnt)
)
SELECT
    mes,
    ano,
    valor_mes,
    LAG(valor_mes) OVER (ORDER BY ano, mes) AS valor_mes_anterior,
    LEAD(valor_mes) OVER (ORDER BY ano, mes) AS valor_mes_seguinte,
    valor_mes - LAG(valor_mes) OVER (ORDER BY ano, mes) AS variacao_mes_anterior
FROM ComprasMensais
ORDER BY ano, mes
```

</details>

---

#### EX25: SUM OVER - Total Acumulado e Participa√ß√£o Percentual

**Objetivo:** Calcular valor acumulado m√™s a m√™s e percentual sobre o total do per√≠odo

**Retornar:** M√™s, Ano, Valor Mensal, Acumulado at√© o M√™s, Percentual sobre Total do Semestre, Total do Semestre.

**Crit√©rios:** Primeiro semestre de 2025.

<details>
<summary>üìù Ver Resposta</summary>

```sql
WITH ComprasMensais AS (
    SELECT
        MONTH(nfc.DatEnt) AS mes,
        YEAR(nfc.DatEnt) AS ano,
        SUM(nfc.VlrLiq) AS valor_mensal
    FROM E440NFC AS nfc
    WHERE nfc.DatEnt BETWEEN '20250101' AND '20250630'
    GROUP BY MONTH(nfc.DatEnt), YEAR(nfc.DatEnt)
)
SELECT
    mes,
    ano,
    valor_mensal,
    SUM(valor_mensal) OVER (ORDER BY ano, mes) AS valor_acumulado,
    SUM(valor_mensal) OVER () AS total_semestre,
    ROUND((valor_mensal / SUM(valor_mensal) OVER ()) * 100, 2) AS percentual_total
FROM ComprasMensais
ORDER BY ano, mes
```

</details>

---

### Bloco 6: Complementares (UNION, Subconsultas, DML) ‚≠ê‚≠ê‚≠ê

#### EX26: UNION B√°sico - Listar Todos os Itens de Compra

**Objetivo:** Combinar produtos e servi√ßos em uma √∫nica lista usando UNION

**Retornar:** Tipo (Produto ou Servi√ßo), C√≥digo do Item, N√∫mero da NF, Valor.

**Crit√©rios:** M√™s de Janeiro 2025, ordenar por tipo e valor.

---

#### EX27: Subconsulta Simples - Notas Acima da M√©dia

**Objetivo:** Usar subconsulta para filtrar notas fiscais com valor acima da m√©dia do per√≠odo

**Retornar:** C√≥digo Filial, N√∫mero NF, C√≥digo Fornecedor, Valor da Nota, M√©dia do Per√≠odo.

**Crit√©rios:** Primeiro trimestre de 2025.

---

#### EX28: EXISTS B√°sico - Fornecedores com Compras no Per√≠odo

**Objetivo:** Identificar fornecedores que tiveram pelo menos uma compra no per√≠odo usando EXISTS

**Retornar:** C√≥digo Fornecedor, Nome Fornecedor, Cidade, UF.

**Crit√©rios:** Fornecedores com compras em Janeiro 2025.

---

#### EX29: Fun√ß√µes de String e Data B√°sicas - Formata√ß√£o de Fornecedores

**Objetivo:** Aplicar fun√ß√µes de string e data para formatar e filtrar informa√ß√µes

**Retornar:** C√≥digo Fornecedor, Nome em Mai√∫sculo, Primeiros 20 caracteres do Nome, Data da √öltima Compra, Dias desde a √öltima Compra.

**Crit√©rios:** Fornecedores que compraram nos √∫ltimos 90 dias, nome cont√©m "COMERCIO".

---

#### EX30: INSERT SELECT B√°sico - Tabela Resumo de Fornecedores

**Objetivo:** Criar tabela tempor√°ria e inserir dados resumidos usando INSERT SELECT

**Retornar:** Tabela com totais por fornecedor para an√°lise.

**Crit√©rios:** Janeiro 2025, criar resumo simples.

---

### 6.2. Exerc√≠cios Python para An√°lise de Dados

---

#### 6.2.1. Bloco 1: Sintaxe B√°sica {#621-bloco-1-sintaxe-basica}

##### Exerc√≠cio 1.1 - Configura√ß√µes de DAG üü¢
**Contexto:** Toda DAG do Airflow precisa de configura√ß√µes b√°sicas.  
**Objetivo:** Trabalhar com dicion√°rios e tipos de dados.
```python
# Configura√ß√£o de uma DAG
dag_config = {
    "dag_id": "process_sales",
    "schedule_interval": "0 8 * * *",
    "retries": 3,
    "active": True,
    "tags": ["vendas", "diario"]
}

# TODO:
# 1. Imprimir o nome da DAG
# 2. Verificar se a DAG est√° ativa (True/False)
# 3. Adicionar uma nova tag "producao" √† lista de tags
# 4. Alterar o n√∫mero de retries para 5
# 5. Imprimir a configura√ß√£o completa
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Nome da DAG
print(f"DAG: {dag_config['dag_id']}")  # DAG: process_sales

# 2. Verificar se est√° ativa
print(f"Ativa: {dag_config['active']}")  # Ativa: True

# 3. Adicionar tag
dag_config['tags'].append('producao')
print(f"Tags: {dag_config['tags']}")  # ['vendas', 'diario', 'producao']

# 4. Alterar retries
dag_config['retries'] = 5

# 5. Configura√ß√£o completa
print(dag_config)
```

**Conceitos aplicados:**
- Dicion√°rios (acesso por chave)
- Tipos de dados (string, int, bool, list)
- M√©todos de lista (`.append()`)

</details>

---

##### Exerc√≠cio 1.2 - Lista de Tabelas para Processar üü¢
**Contexto:** Em pipelines, frequentemente processamos m√∫ltiplas tabelas.  
**Objetivo:** Manipular listas e usar loops b√°sicos.
```python
# Tabelas a serem extra√≠das do SQL Server
tabelas = ["e095for", "e440nfc", "e660inv", "e640lct", "e045pla"]

# TODO:
# 1. Contar quantas tabelas existem
# 2. Imprimir a primeira e a √∫ltima tabela
# 3. Verificar se "e640lct" est√° na lista
# 4. Adicionar a tabela "e075age" ao final
# 5. Criar um loop que imprima: "Processando tabela: [nome]"
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Contar tabelas
print(f"Total: {len(tabelas)} tabelas")  # Total: 5 tabelas

# 2. Primeira e √∫ltima
print(f"Primeira: {tabelas[0]}")   # Primeira: e095for
print(f"√öltima: {tabelas[-1]}")    # √öltima: e045pla

# 3. Verificar se existe
existe = "e640lct" in tabelas
print(f"e640lct existe: {existe}")  # True

# 4. Adicionar tabela
tabelas.append("e075age")

# 5. Loop para processar
for tabela in tabelas:
    print(f"Processando tabela: {tabela}")
```

**Conceitos aplicados:**
- Listas (indexa√ß√£o, tamanho)
- Operador `in` para verifica√ß√£o
- Loop `for` b√°sico
- f-strings para formata√ß√£o

</details>

---

##### Exerc√≠cio 1.3 - Valida√ß√£o de Schemas dbt üü°
**Contexto:** No dbt, organizamos modelos em schemas (raw, staging, marts).  
**Objetivo:** Usar condicionais e estruturas de controle.

```python
# Modelo dbt e seu schema
modelo = "stg_fornecedores"
schema_atual = "staging"

# Regras de nomenclatura:
# - Modelos "raw_" devem estar em schema "raw"
# - Modelos "stg_" devem estar em schema "staging"
# - Modelos "fct_" ou "dim_" devem estar em schema "marts"

# TODO:
# 1. Extrair o prefixo do modelo (parte antes do "_")
# 2. Determinar o schema esperado baseado no prefixo
# 3. Verificar se o schema atual est√° correto
# 4. Imprimir mensagem de valida√ß√£o
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Extrair prefixo
prefixo = modelo.split("_")[0]
print(f"Prefixo: {prefixo}")  # Prefixo: stg

# 2. Determinar schema esperado
if prefixo == "raw":
    schema_esperado = "raw"
elif prefixo == "stg":
    schema_esperado = "staging"
elif prefixo in ["fct", "dim"]:
    schema_esperado = "marts"
else:
    schema_esperado = "desconhecido"

print(f"Schema esperado: {schema_esperado}")  # staging

# 3 e 4. Validar
if schema_atual == schema_esperado:
    print(f"‚úì Modelo '{modelo}' est√° no schema correto: {schema_atual}")
else:
    print(f"‚úó ERRO: Modelo '{modelo}' deveria estar em '{schema_esperado}', mas est√° em '{schema_atual}'")
```

**Conceitos aplicados:**
- String methods (`.split()`)
- Condicionais (`if/elif/else`)
- Operador `in` para m√∫ltiplos valores
- Compara√ß√£o de igualdade

</details>

---

##### Exerc√≠cio 1.4 - Filtragem de Tabelas por Crit√©rio üü°
**Contexto:** √Äs vezes queremos processar apenas tabelas espec√≠ficas.  
**Objetivo:** Combinar listas, loops e condicionais.

```python
# Todas as tabelas dispon√≠veis
todas_tabelas = [
    "e095for", "e440nfc", "e660inv", "e640lct", 
    "e045pla", "e075age", "e001tns", "e070emp"
]

# Crit√©rios de filtro
processar_apenas = ["e095for", "e640lct", "e045pla"]  # Lista espec√≠fica
iniciam_com = "e0"  # Prefixo

# TODO:
# 1. Criar lista com tabelas que est√£o em 'processar_apenas'
# 2. Criar lista com tabelas que come√ßam com 'e0'
# 3. Criar lista com tabelas que atendem AMBOS os crit√©rios
# 4. Imprimir quantas tabelas foram selecionadas em cada caso
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Tabelas na lista espec√≠fica
tabelas_especificas = []
for tabela in todas_tabelas:
    if tabela in processar_apenas:
        tabelas_especificas.append(tabela)

print(f"Espec√≠ficas: {tabelas_especificas}")
# ['e095for', 'e640lct', 'e045pla']

# 2. Tabelas que come√ßam com 'e0'
tabelas_prefixo = []
for tabela in todas_tabelas:
    if tabela.startswith(iniciam_com):
        tabelas_prefixo.append(tabela)

print(f"Com prefixo 'e0': {tabelas_prefixo}")
# ['e095for', 'e045pla', 'e075age', 'e001tns', 'e070emp']

# 3. Tabelas que atendem AMBOS
tabelas_ambos = []
for tabela in todas_tabelas:
    if tabela in processar_apenas and tabela.startswith(iniciam_com):
        tabelas_ambos.append(tabela)

print(f"Ambos crit√©rios: {tabelas_ambos}")
# ['e095for', 'e045pla']

# 4. Contagem
print(f"\nResumo:")
print(f"- Espec√≠ficas: {len(tabelas_especificas)} tabelas")
print(f"- Com prefixo: {len(tabelas_prefixo)} tabelas")
print(f"- Ambos: {len(tabelas_ambos)} tabelas")
```

**Conceitos aplicados:**
- Loops aninhados com condicionais
- String method (`.startswith()`)
- Operadores l√≥gicos (`and`)
- Listas vazias e `.append()`

</details>

---

##### Exerc√≠cio 1.5 - Construtor de Task IDs Din√¢micos üî¥
**Contexto:** No Airflow, cada task precisa de um ID √∫nico. Ao processar m√∫ltiplas tabelas, geramos IDs automaticamente.  
**Objetivo:** Combinar loops, strings, dicion√°rios e l√≥gica condicional.

```python
# Tabelas e suas configura√ß√µes
tabelas_config = {
    "e095for": {"tipo": "incremental", "schema": "raw"},
    "e440nfc": {"tipo": "full", "schema": "raw"},
    "e640lct": {"tipo": "incremental", "schema": "staging"},
    "e045pla": {"tipo": "full", "schema": "marts"}
}

# Padr√£o de task_id: {tipo}_{schema}_{tabela}
# Exemplo: "incremental_raw_e095for"

# TODO:
# 1. Criar dicion√°rio onde a chave √© o task_id e o valor √© o nome da tabela
# 2. Criar lista apenas com task_ids de tabelas incrementais
# 3. Contar quantas tasks existem por schema
# 4. Imprimir relat√≥rio formatado com todas as informa√ß√µes
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Dicion√°rio de task_ids
task_mapping = {}
for tabela, config in tabelas_config.items():
    task_id = f"{config['tipo']}_{config['schema']}_{tabela}"
    task_mapping[task_id] = tabela

print("Task IDs criados:")
for task_id, tabela in task_mapping.items():
    print(f"  {task_id} -> {tabela}")

# 2. Tasks incrementais apenas
tasks_incrementais = []
for tabela, config in tabelas_config.items():
    if config['tipo'] == 'incremental':
        task_id = f"{config['tipo']}_{config['schema']}_{tabela}"
        tasks_incrementais.append(task_id)

print(f"\nTasks incrementais: {tasks_incrementais}")

# 3. Contar por schema
contador_schema = {}
for tabela, config in tabelas_config.items():
    schema = config['schema']
    if schema in contador_schema:
        contador_schema[schema] += 1
    else:
        contador_schema[schema] = 1

print(f"\nTasks por schema: {contador_schema}")

# 4. Relat√≥rio completo
print("\n" + "="*50)
print("RELAT√ìRIO DE TASKS")
print("="*50)
print(f"Total de tasks: {len(task_mapping)}")
print(f"Tasks incrementais: {len(tasks_incrementais)}")
print(f"Tasks full refresh: {len(task_mapping) - len(tasks_incrementais)}")
print("\nDistribui√ß√£o por schema:")
for schema, count in contador_schema.items():
    print(f"  - {schema}: {count} tasks")
```

**Conceitos aplicados:**
- Dicion√°rios aninhados (`.items()`)
- Cria√ß√£o din√¢mica de chaves em dicion√°rio
- Contadores com dicion√°rio
- M√∫ltiplos loops independentes
- Formata√ß√£o de strings complexa
- Opera√ß√µes aritm√©ticas com contadores

</details>

---

#### 6.2.2. Bloco 2: Recursos da Linguagem {#622-bloco-2-recursos-da-linguagem}

##### Exerc√≠cio 2.1 - List Comprehension para Task IDs üü¢
**Contexto:** Gerar listas de forma concisa √© essencial em Python.  
**Objetivo:** Transformar loops em list comprehensions.

```python
# Lista de tabelas
tabelas = ["e095for", "e440nfc", "e660inv", "e640lct", "e045pla"]

# TODO (usando list comprehension):
# 1. Criar lista de task_ids no formato "extract_{tabela}"
# 2. Criar lista apenas com tabelas que come√ßam com "e6"
# 3. Criar lista com o tamanho (length) de cada nome de tabela
# 4. Criar lista de tuplas (tabela, tamanho)
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Task IDs
task_ids = [f"extract_{tabela}" for tabela in tabelas]
print(task_ids)
# ['extract_e095for', 'extract_e440nfc', 'extract_e660inv', 'extract_e640lct', 'extract_e045pla']

# 2. Filtrar por prefixo
tabelas_e6 = [t for t in tabelas if t.startswith("e6")]
print(tabelas_e6)
# ['e660inv', 'e640lct']

# 3. Tamanhos
tamanhos = [len(t) for t in tabelas]
print(tamanhos)
# [7, 7, 7, 7, 7]

# 4. Tuplas (tabela, tamanho)
tabelas_tamanhos = [(t, len(t)) for t in tabelas]
print(tabelas_tamanhos)
# [('e095for', 7), ('e440nfc', 7), ('e660inv', 7), ('e640lct', 7), ('e045pla', 7)]
```

**Conceitos aplicados:**
- List comprehension b√°sica
- List comprehension com filtro (`if`)
- Express√µes dentro de comprehension
- Cria√ß√£o de tuplas em comprehension

</details>

---

##### Exerc√≠cio 2.2 - Dictionary Comprehension para Configs üü¢
**Contexto:** Criar dicion√°rios de configura√ß√£o rapidamente.  
**Objetivo:** Usar dictionary comprehension.

```python
# Lista de modelos dbt
modelos = ["stg_fornecedores", "stg_produtos", "stg_vendas"]

# Configura√ß√£o padr√£o
config_padrao = {
    "materialized": "view",
    "schema": "staging"
}

# TODO (usando dictionary comprehension):
# 1. Criar dicion√°rio {modelo: "view"} para cada modelo
# 2. Criar dicion√°rio {modelo: len(modelo)} com tamanho do nome
# 3. Criar dicion√°rio {modelo: config_padrao} para cada modelo
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Modelo -> materializa√ß√£o
materializacoes = {modelo: "view" for modelo in modelos}
print(materializacoes)
# {'stg_fornecedores': 'view', 'stg_produtos': 'view', 'stg_vendas': 'view'}

# 2. Modelo -> tamanho
tamanhos = {modelo: len(modelo) for modelo in modelos}
print(tamanhos)
# {'stg_fornecedores': 17, 'stg_produtos': 12, 'stg_vendas': 10}

# 3. Modelo -> config completa
configs = {modelo: config_padrao.copy() for modelo in modelos}
print(configs)
# {'stg_fornecedores': {'materialized': 'view', 'schema': 'staging'}, ...}

# Nota: .copy() √© importante para n√£o compartilhar a mesma refer√™ncia
```

**Conceitos aplicados:**
- Dictionary comprehension b√°sica
- Express√µes em dictionary comprehension
- `.copy()` para dicion√°rios (refer√™ncia vs c√≥pia)

</details>

---

##### Exerc√≠cio 2.3 - Simulando o Decorator @task üü°
**Contexto:** O Airflow usa `@task` para transformar fun√ß√µes em tasks.  
**Objetivo:** Entender o conceito de decorators.

```python
# Simula√ß√£o simplificada do comportamento do @task do Airflow

def criar_task(func):
    """Decorator que adiciona metadados √† fun√ß√£o"""
    def wrapper(*args, **kwargs):
        print(f"[TASK START] Executando: {func.__name__}")
        resultado = func(*args, **kwargs)
        print(f"[TASK END] Finalizado: {func.__name__}")
        return resultado
    
    wrapper.task_id = func.__name__
    return wrapper

# TODO:
# 1. Criar fun√ß√£o 'extrair_dados' que retorna "dados extra√≠dos"
# 2. Aplicar o decorator 'criar_task' nela usando @
# 3. Criar fun√ß√£o 'transformar_dados' que recebe dados e retorna f"{dados} transformados"
# 4. Aplicar o decorator tamb√©m
# 5. Executar ambas e observar os logs
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
@criar_task
def extrair_dados():
    return "dados extra√≠dos"

@criar_task
def transformar_dados(dados):
    return f"{dados} transformados"

# Executando as tasks
print("\n--- Execu√ß√£o do Pipeline ---")
dados = extrair_dados()
print(f"Resultado: {dados}\n")

resultado_final = transformar_dados(dados)
print(f"Resultado: {resultado_final}\n")

# Acessando metadados
print(f"Task ID 1: {extrair_dados.task_id}")
print(f"Task ID 2: {transformar_dados.task_id}")

# Output:
# --- Execu√ß√£o do Pipeline ---
# [TASK START] Executando: extrair_dados
# [TASK END] Finalizado: extrair_dados
# Resultado: dados extra√≠dos
#
# [TASK START] Executando: transformar_dados
# [TASK END] Finalizado: transformar_dados
# Resultado: dados extra√≠dos transformados
#
# Task ID 1: extrair_dados
# Task ID 2: transformar_dados
```

**Conceitos aplicados:**
- Decorators (conceito e sintaxe `@`)
- Fun√ß√µes como objetos
- `*args` e `**kwargs`
- Atributos de fun√ß√µes

</details>

---

##### Exerc√≠cio 2.4 - Context Manager para Conex√µes üü°
**Contexto:** Gerenciar conex√µes com bancos requer abertura e fechamento adequados.  
**Objetivo:** Usar context managers (`with`).

```python
class ConexaoSimulada:
    """Simula uma conex√£o de banco de dados"""
    
    def __init__(self, nome_conexao):
        self.nome = nome_conexao
        self.conectado = False
    
    def __enter__(self):
        """Executado ao entrar no bloco 'with'"""
        print(f"[CONNECT] Abrindo conex√£o: {self.nome}")
        self.conectado = True
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Executado ao sair do bloco 'with'"""
        print(f"[DISCONNECT] Fechando conex√£o: {self.nome}")
        self.conectado = False
    
    def executar(self, query):
        if self.conectado:
            print(f"[QUERY] Executando: {query}")
            return f"Resultado de '{query}'"
        else:
            return "ERRO: Conex√£o fechada"

# TODO:
# 1. Usar context manager para conectar ao "redshift"
# 2. Executar query "SELECT * FROM tabela"
# 3. Tentar executar query fora do bloco 'with' e observar erro
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1 e 2. Usando context manager corretamente
print("=== Uso correto ===")
with ConexaoSimulada("redshift") as conn:
    resultado = conn.executar("SELECT * FROM tabela")
    print(f"Retorno: {resultado}")
    print(f"Status dentro: conectado={conn.conectado}")

print(f"Status fora: conectado={conn.conectado}\n")

# 3. Tentando usar fora do contexto (erro)
print("=== Uso incorreto ===")
conexao = ConexaoSimulada("redshift")
print(conexao.executar("SELECT * FROM outra_tabela"))

# Output:
# === Uso correto ===
# [CONNECT] Abrindo conex√£o: redshift
# [QUERY] Executando: SELECT * FROM tabela
# Retorno: Resultado de 'SELECT * FROM tabela'
# Status dentro: conectado=True
# [DISCONNECT] Fechando conex√£o: redshift
# Status fora: conectado=False
#
# === Uso incorreto ===
# ERRO: Conex√£o fechada
```

**Conceitos aplicados:**
- Context managers (`with`)
- `__enter__` e `__exit__`
- Gerenciamento autom√°tico de recursos
- Estados de objetos

</details>

---

##### Exerc√≠cio 2.5 - Pipeline Completo com M√∫ltiplos Conceitos üî¥
**Contexto:** Construir um pipeline que combina todos os conceitos aprendidos.  
**Objetivo:** Integrar comprehensions, decorators e context managers.

```python
# Decorator para logging
def log_task(func):
    def wrapper(*args, **kwargs):
        print(f"‚Üí Iniciando: {func.__name__}")
        resultado = func(*args, **kwargs)
        print(f"‚úì Conclu√≠do: {func.__name__}")
        return resultado
    return wrapper

# Context manager (j√° definido anteriormente)
class ConexaoSimulada:
    def __init__(self, nome):
        self.nome = nome
    
    def __enter__(self):
        print(f"[DB] Conectando a {self.nome}")
        return self
    
    def __exit__(self, *args):
        print(f"[DB] Desconectando de {self.nome}")
    
    def buscar_tabelas(self):
        return ["e095for", "e440nfc", "e640lct"]

# TODO:
# 1. Criar fun√ß√£o decorada 'obter_tabelas_filtradas' que:
#    - Recebe uma conex√£o e um prefixo
#    - Busca tabelas da conex√£o
#    - Retorna apenas tabelas que come√ßam com o prefixo (usar comprehension)
#
# 2. Criar fun√ß√£o decorada 'gerar_task_ids' que:
#    - Recebe lista de tabelas
#    - Retorna dicion√°rio {tabela: task_id} usando dict comprehension
#    - task_id formato: "process_{tabela}"
#
# 3. Executar pipeline completo:
#    - Abrir conex√£o com context manager
#    - Filtrar tabelas (prefixo "e6")
#    - Gerar task_ids
#    - Imprimir resultado
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
@log_task
def obter_tabelas_filtradas(conexao, prefixo):
    todas = conexao.buscar_tabelas()
    filtradas = [t for t in todas if t.startswith(prefixo)]
    return filtradas

@log_task
def gerar_task_ids(tabelas):
    return {tabela: f"process_{tabela}" for tabela in tabelas}

# Pipeline completo
print("="*50)
print("EXECUTANDO PIPELINE")
print("="*50)

with ConexaoSimulada("mssql_source") as db:
    # Etapa 1: Filtrar tabelas
    tabelas = obter_tabelas_filtradas(db, "e6")
    print(f"Tabelas filtradas: {tabelas}\n")
    
    # Etapa 2: Gerar task_ids
    tasks = gerar_task_ids(tabelas)
    print(f"Tasks geradas:")
    for tabela, task_id in tasks.items():
        print(f"  {tabela} ‚Üí {task_id}")

print("\n" + "="*50)
print("PIPELINE FINALIZADO")
print("="*50)

# Output:
# ==================================================
# EXECUTANDO PIPELINE
# ==================================================
# [DB] Conectando a mssql_source
# ‚Üí Iniciando: obter_tabelas_filtradas
# ‚úì Conclu√≠do: obter_tabelas_filtradas
# Tabelas filtradas: ['e640lct']
#
# ‚Üí Iniciando: gerar_task_ids
# ‚úì Conclu√≠do: gerar_task_ids
# Tasks geradas:
#   e640lct ‚Üí process_e640lct
# [DB] Desconectando de mssql_source
#
# ==================================================
# PIPELINE FINALIZADO
# ==================================================
```

**Conceitos aplicados:**
- M√∫ltiplos decorators
- List comprehension com filtro
- Dictionary comprehension
- Context manager
- Composi√ß√£o de fun√ß√µes
- Pipeline de dados

</details>

---

#### 6.2.3. Bloco 3: Pandas para An√°lise Explorat√≥ria {#623-bloco-3-pandas-para-analise-exploratoria}

##### Exerc√≠cio 3.1 - Lendo CSV de Configura√ß√£o üü¢
**Contexto:** Arquivos CSV frequentemente armazenam configura√ß√µes de pipelines.  
**Objetivo:** Ler e explorar DataFrames b√°sicos.

```python
import pandas as pd
from io import StringIO

# Simulando um CSV de depend√™ncias (como nrt_dependencies.csv)
csv_data = """tabela_origem;tabela_destino;tipo_carga
e095for;stg_fornecedores;incremental
e440nfc;stg_notas_fiscais;incremental
e640lct;stg_lancamentos;full
e045pla;stg_plano_contas;full
e660inv;stg_inventario;incremental"""

# TODO:
# 1. Ler o CSV em um DataFrame (sep=";")
# 2. Exibir as primeiras 3 linhas
# 3. Exibir informa√ß√µes sobre o DataFrame (.info())
# 4. Exibir os nomes das colunas
# 5. Contar quantas linhas existem
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Ler CSV
df = pd.read_csv(StringIO(csv_data), sep=";")

# 2. Primeiras 3 linhas
print("Primeiras 3 linhas:")
print(df.head(3))
print()

# 3. Informa√ß√µes
print("Informa√ß√µes do DataFrame:")
df.info()
print()

# 4. Nomes das colunas
print(f"Colunas: {list(df.columns)}")
# ['tabela_origem', 'tabela_destino', 'tipo_carga']

# 5. Contagem
print(f"Total de linhas: {len(df)}")  # 5
```

**Conceitos aplicados:**
- `pd.read_csv()` com separador customizado
- `.head()` para preview
- `.info()` para metadados
- `.columns` para nomes de colunas
- `len()` para contar linhas

</details>

---

##### Exerc√≠cio 3.2 - Filtragem de Dados üü¢
**Contexto:** Filtrar configura√ß√µes por tipo de carga √© comum.  
**Objetivo:** Usar filtros booleanos em DataFrames.

```python
import pandas as pd
from io import StringIO

csv_data = """tabela_origem;tabela_destino;tipo_carga;schema
e095for;stg_fornecedores;incremental;staging
e440nfc;stg_notas_fiscais;incremental;staging
e640lct;stg_lancamentos;full;staging
e045pla;dim_plano_contas;full;marts
e660inv;stg_inventario;incremental;staging"""

df = pd.read_csv(StringIO(csv_data), sep=";")

# TODO:
# 1. Filtrar apenas linhas com tipo_carga = "incremental"
# 2. Filtrar apenas linhas do schema "staging"
# 3. Filtrar linhas incremental E staging (ambos)
# 4. Contar quantas linhas t√™m tipo "full"
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Apenas incrementais
incrementais = df[df['tipo_carga'] == 'incremental']
print("Incrementais:")
print(incrementais)
print()

# 2. Apenas staging
staging = df[df['schema'] == 'staging']
print("Schema staging:")
print(staging)
print()

# 3. Incremental E staging
inc_stg = df[(df['tipo_carga'] == 'incremental') & (df['schema'] == 'staging')]
print("Incremental + Staging:")
print(inc_stg)
print()

# 4. Contar tipo "full"
count_full = len(df[df['tipo_carga'] == 'full'])
print(f"Quantidade de tipo 'full': {count_full}")  # 2
```

**Conceitos aplicados:**
- Filtros booleanos (`df[condicao]`)
- Operadores de compara√ß√£o (`==`)
- Operadores l√≥gicos (`&` para AND)
- Par√™nteses em filtros m√∫ltiplos

</details>

---

##### Exerc√≠cio 3.3 - Sele√ß√£o e Transforma√ß√£o de Colunas üü°
**Contexto:** Preparar dados para gerar tasks dinamicamente.  
**Objetivo:** Selecionar colunas e criar novas.

```python
import pandas as pd
from io import StringIO

csv_data = """tabela_origem;tabela_destino;tipo_carga;schema
e095for;stg_fornecedores;incremental;staging
e440nfc;stg_notas_fiscais;incremental;staging
e640lct;stg_lancamentos;full;staging
e045pla;dim_plano_contas;full;marts"""

df = pd.read_csv(StringIO(csv_data), sep=";")

# TODO:
# 1. Selecionar apenas colunas 'tabela_origem' e 'tipo_carga'
# 2. Criar nova coluna 'task_id' no formato: "{tipo_carga}_{tabela_origem}"
# 3. Criar nova coluna 'prefixo' com os 3 primeiros caracteres de tabela_origem
# 4. Exibir o DataFrame final com todas as colunas
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Selecionar colunas
df_selecionado = df[['tabela_origem', 'tipo_carga']]
print("Colunas selecionadas:")
print(df_selecionado)
print()

# 2. Criar coluna task_id
df['task_id'] = df['tipo_carga'] + '_' + df['tabela_origem']

# 3. Criar coluna prefixo
df['prefixo'] = df['tabela_origem'].str[:3]

# 4. DataFrame completo
print("DataFrame com novas colunas:")
print(df)

# Output:
#   tabela_origem  tabela_destino     tipo_carga  schema                    task_id prefixo
# 0       e095for  stg_fornecedores  incremental staging  incremental_e095for    e09
# 1       e440nfc  stg_notas_fiscais incremental staging  incremental_e440nfc    e44
# 2       e640lct  stg_lancamentos          full staging          full_e640lct    e64
# 3       e045pla  dim_plano_contas        full   marts          full_e045pla    e04
```

**Conceitos aplicados:**
- Sele√ß√£o de colunas (`df[['col1', 'col2']]`)
- Cria√ß√£o de colunas com opera√ß√µes
- Concatena√ß√£o de strings em Series
- `.str` accessor para m√©todos de string

</details>

---

##### Exerc√≠cio 3.4 - Agrupamento e Agrega√ß√£o üü°
**Contexto:** Analisar distribui√ß√£o de tasks por schema ou tipo.  
**Objetivo:** Usar `groupby()` e agrega√ß√µes.
```python
import pandas as pd
from io import StringIO

csv_data = """tabela;schema;tipo_carga;prioridade
e095for;staging;incremental;1
e440nfc;staging;incremental;1
e640lct;staging;full;2
e045pla;marts;full;2
e660inv;staging;incremental;1
e001tns;raw;full;3
e070emp;raw;incremental;2"""

df = pd.read_csv(StringIO(csv_data), sep=";")

# TODO:
# 1. Contar quantas tabelas existem por schema
# 2. Contar quantas tabelas existem por tipo_carga
# 3. Calcular a prioridade m√©dia por schema
# 4. Criar tabela cruzada: schema vs tipo_carga (contagem)
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Contagem por schema
por_schema = df.groupby('schema')['tabela'].count()
print("Tabelas por schema:")
print(por_schema)
print()
# staging    4
# marts      1
# raw        2

# 2. Contagem por tipo_carga
por_tipo = df.groupby('tipo_carga')['tabela'].count()
print("Tabelas por tipo_carga:")
print(por_tipo)
print()
# full           3
# incremental    4

# 3. Prioridade m√©dia por schema
prioridade_media = df.groupby('schema')['prioridade'].mean()
print("Prioridade m√©dia por schema:")
print(prioridade_media)
print()
# staging    1.25
# marts      2.00
# raw        2.50

# 4. Tabela cruzada
tabela_cruzada = pd.crosstab(df['schema'], df['tipo_carga'])
print("Schema vs Tipo (contagem):")
print(tabela_cruzada)
# tipo_carga   full  incremental
# schema                        
# marts           1            0
# raw             1            1
# staging         1            3
```

**Conceitos aplicados:**
- `.groupby()` para agrupamento
- Agrega√ß√µes (`.count()`, `.mean()`)
- `pd.crosstab()` para tabelas cruzadas
- An√°lise multidimensional

</details>

---

##### Exerc√≠cio 3.5 - Itera√ß√£o para Gera√ß√£o de Tasks üî¥
**Contexto:** Converter DataFrame em estruturas para criar tasks do Airflow dinamicamente.  
**Objetivo:** Iterar sobre DataFrame e construir dicion√°rios/listas complexas.

```python
import pandas as pd
from io import StringIO

csv_data = """tabela_origem;tabela_destino;tipo_carga;schema;dependencias
e095for;stg_fornecedores;incremental;staging;
e440nfc;stg_notas_fiscais;incremental;staging;e095for
e640lct;stg_lancamentos;full;staging;e440nfc
e045pla;dim_plano_contas;full;marts;e640lct;e095for
e660inv;fct_inventario;incremental;marts;e045pla;e440nfc"""

df = pd.read_csv(StringIO(csv_data), sep=";")

# TODO:
# 1. Converter DataFrame em lista de dicion√°rios
# 2. Para cada linha, criar estrutura:
#    {
#        "task_id": "{tipo_carga}_{tabela_origem}",
#        "source": "tabela_origem",
#        "target": "tabela_destino",
#        "dependencies": ["dep1", "dep2"]  # split por ";"
#    }
# 3. Filtrar apenas tasks do schema "staging"
# 4. Criar dicion√°rio final: {task_id: task_config}
# 5. Imprimir em formato leg√≠vel
```

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```python
# 1. Converter para lista de dicion√°rios
registros = df.to_dict('records')

# 2. Criar estrutura de tasks
tasks = []
for row in registros:
    # Processar depend√™ncias (pode ser NaN ou string com ";")
    deps_raw = row['dependencias']
    if pd.isna(deps_raw) or deps_raw == '':
        dependencias = []
    else:
        dependencias = [d.strip() for d in str(deps_raw).split(';')]
    
    task = {
        "task_id": f"{row['tipo_carga']}_{row['tabela_origem']}",
        "source": row['tabela_origem'],
        "target": row['tabela_destino'],
        "schema": row['schema'],
        "dependencies": dependencias
    }
    tasks.append(task)

# 3. Filtrar schema "staging"
tasks_staging = [t for t in tasks if t['schema'] == 'staging']

# 4. Criar dicion√°rio final
task_dict = {task['task_id']: task for task in tasks_staging}

# 5. Imprimir formatado
print("="*60)
print("TASKS CONFIGURADAS (SCHEMA: STAGING)")
print("="*60)
for task_id, config in task_dict.items():
    print(f"\nTask ID: {task_id}")
    print(f"  Source: {config['source']}")
    print(f"  Target: {config['target']}")
    print(f"  Dependencies: {config['dependencies']}")

print("\n" + "="*60)
print(f"Total: {len(task_dict)} tasks")
print("="*60)

# Output:
# ============================================================
# TASKS CONFIGURADAS (SCHEMA: STAGING)
# ============================================================
#
# Task ID: incremental_e095for
#   Source: e095for
#   Target: stg_fornecedores
#   Dependencies: []
#
# Task ID: incremental_e440nfc
#   Source: e440nfc
#   Target: stg_notas_fiscais
#   Dependencies: ['e095for']
#
# Task ID: full_e640lct
#   Source: e640lct
#   Target: stg_lancamentos
#   Dependencies: ['e440nfc']
#
# ============================================================
# Total: 3 tasks
# ============================================================
```

**Conceitos aplicados:**
- `.to_dict('records')` para convers√£o
- Itera√ß√£o sobre DataFrame
- `pd.isna()` para verificar NaN
- `.split()` e `.strip()` para processar strings
- List comprehension para filtragem
- Dictionary comprehension para estrutura final
- Formata√ß√£o de output complexa

</details>

---

## 6.3. Exerc√≠cios DAX {#63-exercicios-dax}

---

### 6.3.1. Bloco 1: Medidas B√°sicas com Filtros {#631-bloco-1-medidas-basicas-com-filtros}

#### Exerc√≠cio 3.1 - Contagem com Filtro Simples üü¢
**Contexto:** No dashboard de contas a receber, precisamos contar t√≠tulos por status.  
**Objetivo:** Praticar COUNT com CALCULATE e filtro direto.

**Dados dispon√≠veis:**
- fat_contas_a_receber (num_titulo, sit_titulo, vlr_original_titulo, dat_vencimento)

**Tarefas:**
1. Criar medida que conta t√≠tulos com status "AB" (aberto)
2. Criar medida que conta t√≠tulos com status "LQ" (liquidado)

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Medida 1: T√≠tulos em Aberto
titulos_em_aberto = 
CALCULATE(
    COUNT(fat_contas_a_receber[num_titulo]),
    fat_contas_a_receber[sit_titulo] = "AB"
)

// Medida 2: T√≠tulos Liquidados
titulos_liquidados = 
CALCULATE(
    COUNT(fat_contas_a_receber[num_titulo]),
    fat_contas_a_receber[sit_titulo] = "LQ"
)
```

**Conceitos aplicados:**
- `COUNT()` - Conta linhas n√£o vazias de uma coluna
- `CALCULATE()` - Modifica o contexto de filtro
- Filtro direto: `tabela[coluna] = "valor"`

</details>

---

#### Exerc√≠cio 3.2 - Soma com Filtro Simples üü¢
**Contexto:** Al√©m de contar, precisamos somar o valor total dos t√≠tulos em aberto.  
**Objetivo:** Praticar SUM com CALCULATE e filtro direto.

**Dados dispon√≠veis:**
- fat_contas_a_receber (num_titulo, sit_titulo, vlr_original_titulo)

**Tarefas:**
1. Criar medida que soma valor de t√≠tulos com status "AB"
2. Criar medida que soma valor de t√≠tulos com status "LQ"

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Medida 1: Valor em Aberto
vlr_titulos_em_aberto = 
CALCULATE(
    SUM(fat_contas_a_receber[vlr_original_titulo]),
    fat_contas_a_receber[sit_titulo] = "AB"
)

// Medida 2: Valor Liquidado
vlr_titulos_liquidados = 
CALCULATE(
    SUM(fat_contas_a_receber[vlr_original_titulo]),
    fat_contas_a_receber[sit_titulo] = "LQ"
)
```

**Conceitos aplicados:**
- `SUM()` - Soma valores de uma coluna
- `CALCULATE()` - Aplica filtro √† agrega√ß√£o
- Filtro em contexto de medida

</details>

---

#### Exerc√≠cio 3.3 - Soma Total com M√∫ltiplos Filtros üü¢
**Contexto:** No dashboard de estoque, precisamos somar gastos por categoria espec√≠fica.  
**Objetivo:** Praticar SUM com CALCULATE e filtro de texto exato.

**Dados dispon√≠veis:**
- fat_gasto_estoque (vlrmov, grupo_epi, grupo_epi_donos)

**Tarefas:**
1. Criar medida que soma gastos onde grupo_epi_donos = "UNIFORMES"
2. Criar medida que soma gastos onde grupo_epi_donos = "EPI"

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Medida 1: Total Uniformes
total_uniformes = 
CALCULATE(
    SUM(fat_gasto_estoque[vlrmov]),
    fat_gasto_estoque[grupo_epi_donos] = "UNIFORMES"
)

// Medida 2: Total EPI
total_epi = 
CALCULATE(
    SUM(fat_gasto_estoque[vlrmov]),
    fat_gasto_estoque[grupo_epi_donos] = "EPI"
)
```

**Conceitos aplicados:**
- `SUM()` com filtro categ√≥rico
- `CALCULATE()` com filtro de texto
- Agrega√ß√£o por grupo

</details>

---

### 6.3.2. Bloco 2: Compara√ß√µes Temporais {#632-bloco-2-comparacoes-temporais}

#### Exerc√≠cio 3.4 - M√™s Anterior üü°
**Contexto:** No dashboard de or√ßamento TI, comparamos realizado atual vs m√™s anterior.  
**Objetivo:** Praticar DATEADD para navegar no tempo.

**Dados dispon√≠veis:**
- orcamento_taina (valor_orcado, valor_realizado)
- dim_calendario (data, mes, ano)

**Tarefas:**
1. Criar medida "Realizado" que soma valor_realizado
2. Criar medida "Realizado M√™s Anterior" usando DATEADD(-1, MONTH)

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Medida base
Realizado = SUM(orcamento_taina[valor_realizado])

// M√™s anterior
Realizado M√™s Anterior = 
CALCULATE(
    [Realizado],
    DATEADD(dim_calendario[data], -1, MONTH)
)
```

**Conceitos aplicados:**
- `DATEADD(coluna_data, quantidade, unidade)` - Navega no tempo
- Unidades: DAY, MONTH, QUARTER, YEAR
- Refer√™ncia de medida: `[nome_medida]`

</details>

---

#### Exerc√≠cio 3.5 - Semana Anterior üü°
**Contexto:** No dashboard de estoque, acompanhamos varia√ß√£o semanal de gastos.  
**Objetivo:** Praticar DATEADD com dias para compara√ß√£o semanal.

**Dados dispon√≠veis:**
- fat_gasto_estoque (vlrmov, data_movimento)
- dim_calendario (data, semana, mes)

**Tarefas:**
1. Criar medida "total" que soma vlrmov
2. Criar medida "total_semana_anterior" usando DATEADD(-7, DAY)

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Medida base
total = SUM(fat_gasto_estoque[vlrmov])

// Semana anterior (7 dias atr√°s)
total_semana_anterior = 
CALCULATE(
    [total],
    DATEADD(dim_calendario[data], -7, DAY)
)
```

**Conceitos aplicados:**
- `DATEADD()` com DAY para dias espec√≠ficos
- -7 dias = semana anterior
- Navega√ß√£o temporal personalizada

</details>

---

#### Exerc√≠cio 3.6 - Varia√ß√£o Percentual üü°
**Contexto:** Precisamos calcular crescimento percentual entre per√≠odos.  
**Objetivo:** Praticar DIVIDE para evitar erros de divis√£o por zero.

**Dados dispon√≠veis:**
- Medidas j√° criadas: [total], [total_semana_anterior]

**Tarefas:**
1. Criar medida "variacao_absoluta" (diferen√ßa simples)
2. Criar medida "variacao_percentual" usando DIVIDE
3. Formatar como percentual

<details>
<summary>üìù Ver Solu√ß√£o</summary>

``dax
// Varia√ß√£o absoluta
variacao_absoluta = [total] - [total_semana_anterior]

// Varia√ß√£o percentual (segura contra divis√£o por zero)
variacao_percentual = 
DIVIDE(
    [total] - [total_semana_anterior],
    [total_semana_anterior],
    0  // valor padr√£o se denominador for zero
)

// Com formata√ß√£o
variacao_percentual_formatada = 
FORMAT(
    [variacao_percentual],
    "0.0%"
)
```

**Conceitos aplicados:**
- `DIVIDE(numerador, denominador, valor_alternativo)` - Divis√£o segura
- Terceiro par√¢metro previne erro #DIV/0
- `FORMAT()` para apresenta√ß√£o

</details>

---

### 6.3.3. Bloco 3: Totalizadores e Contextos {#633-bloco-3-totalizadores-e-contextos}

#### Exerc√≠cio 3.7 - Total Geral (Ignorar Filtros) üü°
**Contexto:** No dashboard de estoque, queremos calcular % sobre o total ignorando filtros visuais.  
**Objetivo:** Praticar REMOVEFILTERS para criar totalizadores globais.

**Dados dispon√≠veis:**
- fat_gasto_estoque (vlrmov, grupo_epi)

**Tarefas:**
1. Criar medida "total" que respeita filtros
2. Criar medida "total_geral" que ignora filtro de grupo_epi
3. Criar medida "percentual_do_total"

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Total normal (respeita filtros)
total = SUM(fat_gasto_estoque[vlrmov])

// Total geral (ignora filtro de grupo)
total_geral = 
CALCULATE(
    SUM(fat_gasto_estoque[vlrmov]),
    REMOVEFILTERS(fat_gasto_estoque[grupo_epi])
)

// Percentual do total
percentual_do_total = 
DIVIDE(
    [total],
    [total_geral]
)
```

**Conceitos aplicados:**
- `REMOVEFILTERS(tabela[coluna])` - Remove filtro espec√≠fico
- `REMOVEFILTERS(tabela)` - Remove todos os filtros da tabela
- Total geral vs total filtrado

</details>

---

#### Exerc√≠cio 3.8 - Subtotal por Categoria üü°
**Contexto:** Queremos total por categoria mantendo outros filtros ativos (per√≠odo, filial).  
**Objetivo:** Praticar ALLEXCEPT para remover filtros seletivamente.

**Dados dispon√≠veis:**
- fat_gasto_estoque (vlrmov, grupo_epi, filial, data)
- dim_calendario (data, mes, ano)

**Tarefas:**
1. Criar medida que soma por grupo_epi
2. Ignorar filtro de grupo_epi MAS manter filtros de per√≠odo e filial

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Total por categoria (mant√©m filtros de per√≠odo/filial)
total_categoria = 
CALCULATE(
    SUM(fat_gasto_estoque[vlrmov]),
    ALLEXCEPT(
        fat_gasto_estoque,
        fat_gasto_estoque[filial],
        dim_calendario[data]
    )
)

// Alternativa usando REMOVEFILTERS
total_categoria_v2 = 
CALCULATE(
    SUM(fat_gasto_estoque[vlrmov]),
    REMOVEFILTERS(fat_gasto_estoque[grupo_epi])
)
```

**Conceitos aplicados:**
- `ALLEXCEPT(tabela, coluna1, coluna2, ...)` - Remove todos EXCETO
- Mant√©m filtros espec√≠ficos enquanto remove outros
- √ötil para subtotais por dimens√£o

</details>

---

### 6.3.4. Bloco 4: Indicadores e L√≥gica Condicional {#634-bloco-4-indicadores-e-logica-condicional}

#### Exerc√≠cio 3.9 - Indicador de Meta üü°
**Contexto:** No dashboard de or√ßamento, queremos indicar se estamos dentro da meta (¬±10%).  
**Objetivo:** Praticar IF com l√≥gica condicional para criar indicadores.

**Dados dispon√≠veis:**
- orcamento_taina (valor_orcado, valor_realizado)

**Tarefas:**
1. Criar medida "delta_percentual" (realizado vs or√ßado)
2. Criar medida "status_meta" que retorna "Dentro" ou "Fora"
3. Meta: varia√ß√£o de at√© ¬±10%

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Base: or√ßado e realizado
Orcado = SUM(orcamento_taina[valor_orcado])
Realizado = SUM(orcamento_taina[valor_realizado])

// Delta percentual
delta_percentual = 
DIVIDE(
    [Realizado] - [Orcado],
    [Orcado],
    0
)

// Status da meta (¬±10%)
status_meta = 
IF(
    ABS([delta_percentual]) <= 0.10,
    "Dentro da Meta",
    "Fora da Meta"
)

// Vers√£o com cores
status_meta_cor = 
IF(
    ABS([delta_percentual]) <= 0.10,
    "üü¢ Dentro",
    "üî¥ Fora"
)
```

**Conceitos aplicados:**
- `IF(teste_l√≥gico, valor_se_verdadeiro, valor_se_falso)`
- `ABS()` - Valor absoluto (ignora sinal)
- L√≥gica condicional para indicadores

</details>

---

#### Exerc√≠cio 3.10 - Cor Condicional Baseada em Crescimento üü°
**Contexto:** No dashboard de estoque, queremos cor verde para crescimento e vermelha para queda.  
**Objetivo:** Praticar IF aninhado para retornar valores condicionais (c√≥digos de cor).

**Dados dispon√≠veis:**
- Medidas j√° criadas: [total], [total_semana_anterior]

**Tarefas:**
1. Calcular diferen√ßa entre per√≠odos
2. Retornar c√≥digo de cor: verde (#008000) para crescimento, vermelho (#FF0000) para queda
3. Retornar BLANK() se n√£o houver dados

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
// Cor baseada em varia√ß√£o semanal
Cor_Indicador_Semanal = 
VAR diferenca = [total] - [total_semana_anterior]
RETURN
    IF(
        ISBLANK(diferenca),
        BLANK(),
        IF(
            diferenca >= 0,
            "#008000",  // Verde (crescimento)
            "#FF0000"   // Vermelho (queda)
        )
    )

// Vers√£o com emoji
Indicador_Visual = 
VAR diferenca = [total] - [total_semana_anterior]
RETURN
    IF(
        ISBLANK(diferenca),
        "",
        IF(
            diferenca >= 0,
            "üü¢ +" & FORMAT(diferenca, "#,##0"),
            "üî¥ " & FORMAT(diferenca, "#,##0")
        )
    )
```

**Conceitos aplicados:**
- `VAR` - Vari√°veis para armazenar valores intermedi√°rios
- `ISBLANK()` - Verifica se valor √© vazio
- IF aninhado para m√∫ltiplas condi√ß√µes
- C√≥digos HEX para cores no Power BI

</details>

---

### 6.3.5. Bloco 5: L√≥gica Avan√ßada e Itera√ß√£o {#635-bloco-5-logica-avancada-e-iteracao}

#### Exerc√≠cio 3.11 - Consist√™ncia Mensal (Meses Dentro da Meta) üî¥
**Contexto:** No dashboard de or√ßamento TI, queremos saber quantos % dos meses ficaram dentro da meta.  
**Objetivo:** Praticar FILTER + SUMMARIZE + COUNTROWS para an√°lise agregada.

**Dados dispon√≠veis:**
- orcamento_taina (valor_orcado, valor_realizado)
- dim_calendario (data, conc_mes, mes, ano)
- Meta: delta de ¬±10%

**Tarefas:**
1. Criar tabela resumida por m√™s com delta %
2. Filtrar apenas meses dentro da meta (¬±10%)
3. Calcular % de meses dentro da meta

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
Consistencia Mensal = 
VAR TabelaMensal = 
    SUMMARIZE(
        dim_calendario,
        dim_calendario[conc_mes],
        "DeltaMes", [delta_percentual]
    )
VAR MesesDentroMeta = 
    COUNTROWS(
        FILTER(
            TabelaMensal,
            ABS([DeltaMes]) <= 0.10
        )
    )
VAR TotalMeses = DISTINCTCOUNT(dim_calendario[conc_mes])
RETURN 
    DIVIDE(MesesDentroMeta, TotalMeses, 0)
```

**Conceitos aplicados:**
- `SUMMARIZE(tabela, coluna_grupo, "nome", medida)` - Cria tabela resumida
- `FILTER(tabela, condi√ß√£o)` - Filtra tabela virtual
- `COUNTROWS()` - Conta linhas de tabela
- `VAR` para organizar l√≥gica complexa

</details>

---

#### Exerc√≠cio 3.12 - Percentual de Ano Decorrido üî¥
**Contexto:** Queremos calcular que % do ano j√° passou para comparar or√ßado vs realizado.  
**Objetivo:** Praticar l√≥gica de data complexa com c√°lculo de dias e ano bissexto.

**Dados dispon√≠veis:**
- dim_calendario (data)

**Tarefas:**
1. Calcular quantos dias se passaram desde 01/jan
2. Calcular total de dias do ano (considerar ano bissexto)
3. Retornar % do ano decorrido

<details>
<summary>üìù Ver Solu√ß√£o</summary>

```dax
% Ano Decorrido = 
VAR DataSelecionada = MAX(dim_calendario[data])
VAR AnoSelecionado = YEAR(DataSelecionada)
VAR InicioAno = DATE(AnoSelecionado, 1, 1)
VAR DiaDoAno = DATEDIFF(InicioAno, DataSelecionada, DAY) + 1
VAR TotalDiasAno = 
    IF(
        MOD(AnoSelecionado, 4) = 0 
        && (MOD(AnoSelecionado, 100) <> 0 || MOD(AnoSelecionado, 400) = 0),
        366,  // Ano bissexto
        365   // Ano normal
    )
RETURN
    DIVIDE(DiaDoAno, TotalDiasAno, 0)
```

**Conceitos aplicados:**
- `YEAR()`, `DATE()` - Fun√ß√µes de data
- `DATEDIFF(data_inicial, data_final, unidade)` - Diferen√ßa entre datas
- `MOD()` - Resto da divis√£o (para detectar ano bissexto)
- L√≥gica complexa de ano bissexto

</details>

---

## 6.4. Exerc√≠cios Linguagem M (Power Query) {#64-exercicios-linguagem-m-power-query}

---

### 6.4.1. Bloco 1: Transforma√ß√µes B√°sicas {#641-bloco-1-transformacoes-basicas}

#### Exerc√≠cio 4.1 - Unpivot de Colunas Mensais üü¢
**Contexto:** Dados de or√ßamento chegam com uma coluna para cada m√™s (jan, fev, mar...).  
**Objetivo:** Entender Table.UnpivotOtherColumns para transformar colunas em linhas.

**C√≥digo fornecido:**

```m
let
    Fonte = Excel.Workbook(...),
    Planilha = Fonte{[Name="orcamento"]}[Data],
    #"Colunas Removidas" = Table.RemoveColumns(Planilha, {"regra", "amostra"}),
    #"Colunas N√£o Din√¢micas" = Table.UnpivotOtherColumns(
        #"Colunas Removidas", 
        {"tipo"}, 
        "Atributo", 
        "Valor"
    )
in
    #"Colunas N√£o Din√¢micas"
```

**Perguntas:**
1. O que faz `Table.UnpivotOtherColumns`?
2. Por que {"tipo"} est√° no segundo par√¢metro?
3. O que significam "Atributo" e "Valor"?

<details>
<summary>üìù Ver Solu√ß√£o</summary>

**Respostas:**

1. **Table.UnpivotOtherColumns**: Transforma m√∫ltiplas colunas em duas colunas (nome + valor)
   - ANTES: `tipo | jan | fev | mar`
   - DEPOIS: `tipo | Atributo | Valor` (3x mais linhas)

2. **{"tipo"}**: Lista de colunas que **N√ÉO** ser√£o dinamizadas
   - Essas colunas permanecem fixas
   - Todas as outras viram linhas

3. **"Atributo" e "Valor"**: Nomes das novas colunas
   - "Atributo": nome da coluna original (jan, fev, mar...)
   - "Valor": conte√∫do da c√©lula

**Exemplo visual:**
```
ANTES:
tipo      | jan_orc | jan_real | fev_orc
UNIFORME  | 1000    | 950      | 1100

DEPOIS:
tipo      | Atributo  | Valor
UNIFORME  | jan_orc   | 1000
UNIFORME  | jan_real  | 950
UNIFORME  | fev_orc   | 1100
```

**Conceitos aplicados:**
- Unpivot (wide ‚Üí long format)
- Colunas fixas vs din√¢micas
- Reestrutura√ß√£o de dados

</details>

---

#### Exerc√≠cio 4.2 - Limpeza e Padroniza√ß√£o de Texto üü¢
**Contexto:** Dados v√™m com texto inconsistente (espa√ßos, min√∫sculas/mai√∫sculas, caracteres especiais).  
**Objetivo:** Entender Text.Upper, Text.Clean, Text.Trim para padronizar.

**C√≥digo fornecido:**

```m
let
    Fonte = Excel.Workbook(...),
    #"Texto em Mai√∫scula" = Table.TransformColumns(
        Fonte,
        {{"tipo", Text.Upper, type text}}
    ),
    #"Texto Limpo" = Table.TransformColumns(
        #"Texto em Mai√∫scula",
        {{"tipo", Text.Clean, type text}}
    ),
    #"Texto Aparado" = Table.TransformColumns(
        #"Texto Limpo",
        {{"tipo", Text.Trim, type text}}
    )
in
    #"Texto Aparado"
```

**Perguntas:**
1. O que faz `Text.Upper`?
2. Qual a diferen√ßa entre `Text.Clean` e `Text.Trim`?
3. Por que a ordem das transforma√ß√µes importa?

<details>
<summary>üìù Ver Solu√ß√£o</summary>

**Respostas:**

1. **Text.Upper**: Converte todo texto para MAI√öSCULAS
   - "uniforme" ‚Üí "UNIFORME"
   - √ötil para padroniza√ß√£o e compara√ß√µes

2. **Diferen√ßa Clean vs Trim**:
   - **Text.Clean**: Remove caracteres n√£o imprim√≠veis (quebras de linha, tabs invis√≠veis)
   - **Text.Trim**: Remove espa√ßos no in√≠cio e fim
   - Exemplo: " texto  \n " ‚Üí Clean: " texto   " ‚Üí Trim: "texto"

3. **Ordem importa**:
   - Primeiro Upper (facilita identificar problemas)
   - Depois Clean (remove sujeira invis√≠vel)
   - Por fim Trim (remove espa√ßos extras)

**Exemplo completo:**
```
ANTES:    "  uniforme  \n"
Upper:    "  UNIFORME  \n"
Clean:    "  UNIFORME  "
Trim:     "UNIFORME"
```

**Conceitos aplicados:**
- Transforma√ß√£o de colunas
- Fun√ß√µes de texto em M
- Pipeline de limpeza

</details>

---

### 6.4.2. Bloco 2: Transforma√ß√µes Intermedi√°rias {#642-bloco-2-transformacoes-intermediarias}

#### Exerc√≠cio 4.3 - Split de Coluna por Delimitador üü°
**Contexto:** Coluna com dados compostos "orc_jan_2025" precisa ser separada.  
**Objetivo:** Entender Table.SplitColumn e Splitter.SplitTextByDelimiter.

**C√≥digo fornecido:**

```m
let
    Fonte = ...,
    #"Dividir Coluna por Delimitador" = Table.SplitColumn(
        Fonte, 
        "Atributo", 
        Splitter.SplitTextByDelimiter("_", QuoteStyle.Csv), 
        {"Atributo.1", "Atributo.2", "Atributo.3"}
    ),
    #"Tipo Alterado" = Table.TransformColumnTypes(
        #"Dividir Coluna por Delimitador",
        {{"Atributo.1", type text}, {"Atributo.2", type text}, {"Atributo.3", Int64.Type}}
    ),
    #"Colunas Removidas" = Table.RemoveColumns(#"Tipo Alterado", {"Atributo.3"}),
    #"Colunas Renomeadas" = Table.RenameColumns(
        #"Colunas Removidas",
        {{"Atributo.1", "Orcado_Real"}, {"Atributo.2", "Mes"}}
    )
in
    #"Colunas Renomeadas"
```

**Perguntas:**
1. O que faz `Splitter.SplitTextByDelimiter("_")`?
2. Por que especificar {"Atributo.1", "Atributo.2", "Atributo.3"}?
3. Por que remover "Atributo.3" depois?

<details>
<summary>üìù Ver Solu√ß√£o</summary>

**Respostas:**

1. **SplitTextByDelimiter("_")**: Divide texto usando "_" como separador
   - "orc_jan_2025" ‚Üí ["orc", "jan", "2025"]
   - Cada parte vira uma coluna

2. **Lista de nomes**: Define nomes das novas colunas resultantes
   - Sem isso: Power Query gera nomes gen√©ricos (Column1, Column2...)
   - Com isso: Nomes descritivos desde o in√≠cio

3. **Remover Atributo.3**: Coluna de ano n√£o era necess√°ria
   - Split gera 3 colunas, mas s√≥ precis√°vamos de 2
   - Remove coluna extra para simplificar

**Transforma√ß√£o visual:**

```
ANTES:
Atributo
orc_jan_2025

SPLIT:
Atributo.1 | Atributo.2 | Atributo.3
orc        | jan        | 2025

DEPOIS (remove .3 e renomeia):
Orcado_Real | Mes
orc         | jan
```

**Conceitos aplicados:**
- Split de texto por delimitador
- Nomea√ß√£o de colunas resultantes
- Limpeza p√≥s-transforma√ß√£o

</details>

---

#### Exerc√≠cio 4.4 - Pivot Ap√≥s Unpivot (Reestrutura√ß√£o) üü°
**Contexto:** Dados foram desempilhados (unpivot), transformados, e precisam voltar para formato wide.  
**Objetivo:** Entender Table.Pivot para inverter unpivot.

**C√≥digo fornecido:**

```m
let
    Fonte = ...,
    #"Unpivot" = Table.UnpivotOtherColumns(Fonte, {"tipo"}, "Metrica", "Valor"),
    #"Split Metrica" = Table.SplitColumn(...),  // separa "orc_jan" em "orc" e "jan"
    #"Renomear" = Table.RenameColumns(..., {{"Atributo.1", "Orcado_Real"}}),
    #"Coluna em piv√¥" = Table.Pivot(
        #"Renomear", 
        List.Distinct(#"Renomear"[Orcado_Real]), 
        "Orcado_Real", 
        "Valor", 
        List.Sum
    )
in
    #"Coluna em piv√¥"
```

**Perguntas:**
1. O que faz `Table.Pivot`?
2. O que significa `List.Distinct(#"Renomear"[Orcado_Real])`?
3. Por que usar `List.Sum` como √∫ltimo par√¢metro?

<details>
<summary>üìù Ver Solu√ß√£o</summary>

**Respostas:**

1. **Table.Pivot**: Transforma linhas em colunas (oposto de unpivot)
   - ANTES (long): `tipo | Orcado_Real | Valor`
   - DEPOIS (wide): `tipo | orc | real`

2. **List.Distinct**: Lista valores √∫nicos da coluna
   - Ex: ["orc", "real"] se coluna tem "orc", "real", "orc", "real"...
   - Define quais ser√£o os nomes das novas colunas

3. **List.Sum**: Fun√ß√£o de agrega√ß√£o para valores duplicados
   - Se houver m√∫ltiplas linhas para mesmo tipo+Orcado_Real, soma valores
   - Outras op√ß√µes: List.Min, List.Max, List.Average

**Transforma√ß√£o visual:**
```
ANTES (long):
tipo      | Orcado_Real | Valor
UNIFORME  | orc         | 1000
UNIFORME  | real        | 950
EPI       | orc         | 500
EPI       | real        | 480

DEPOIS (wide - pivot):
tipo      | orc  | real
UNIFORME  | 1000 | 950
EPI       | 500  | 480
```

**Conceitos aplicados:**
- Pivot (long ‚Üí wide)
- Valores distintos como nomes de colunas
- Agrega√ß√£o em pivot

</details>

---

### 6.4.3. Bloco 3: An√°lise de Pipeline Completo {#643-bloco-3-analise-de-pipeline-completo}

#### Exerc√≠cio 4.5 - Pipeline de Transforma√ß√£o Completo üî¥
**Contexto:** Analisar c√≥digo M real do or√ßamento de laborat√≥rio com m√∫ltiplas transforma√ß√µes encadeadas.  
**Objetivo:** Compreender pipeline completo de ETL no Power Query.

**C√≥digo fornecido (simplificado):**

```m
let
    Fonte = AmazonRedshift.Database("servidor", "database"),
    dbt_marts = Fonte{[Name="dbt_marts"]}[Data],
    fat_orcamento = dbt_marts{[Name="fat_orcamento_laboratorio_custo_fixo"]}[Data],
    
    // 1. Unpivot
    #"Colunas N√£o Din√¢micas" = Table.UnpivotOtherColumns(
        fat_orcamento, 
        {"tipo"}, 
        "Atributo", 
        "Valor"
    ),
    
    // 2. Renomear
    #"Colunas Renomeadas" = Table.RenameColumns(
        #"Colunas N√£o Din√¢micas",
        {{"Atributo", "M√™s"}, {"tipo", "TIPO"}}
    ),
    
    // 3. Split
    #"Dividir Coluna por Delimitador" = Table.SplitColumn(
        #"Colunas Renomeadas", 
        "M√™s", 
        Splitter.SplitTextByDelimiter("_", QuoteStyle.Csv), 
        {"M√™s.1", "M√™s.2", "M√™s.3"}
    ),
    
    // 4. Remover coluna ano
    #"Colunas Removidas" = Table.RemoveColumns(
        #"Dividir Coluna por Delimitador",
        {"M√™s.3"}
    ),
    
    // 5. Renomear split
    #"Colunas Renomeadas1" = Table.RenameColumns(
        #"Colunas Removidas",
        {{"M√™s.1", "Or√ßado Real"}, {"M√™s.2", "M√™s"}}
    ),
    
    // 6. Pivot
    #"Coluna em piv√¥" = Table.Pivot(
        #"Colunas Renomeadas1", 
        List.Distinct(#"Colunas Renomeadas1"[#"Or√ßado Real"]), 
        "Or√ßado Real", 
        "Valor", 
        List.Sum
    ),
    
    // 7. Renomear colunas finais
    #"Colunas Renomeadas2" = Table.RenameColumns(
        #"Coluna em piv√¥",
        {{"orc", "valor_orc2025"}, {"real", "valor_real2025"}}
    ),
    
    // 8. Substituir valores espec√≠ficos
    #"Valor Substitu√≠do" = Table.ReplaceValue(
        #"Colunas Renomeadas2",
        5161.73,
        0,
        Replacer.ReplaceValue,
        {"valor_real2025"}
    ),
    
    // 9. Converter zeros em null
    #"Valor Substitu√≠do2" = Table.ReplaceValue(
        #"Valor Substitu√≠do",
        0,
        null,
        Replacer.ReplaceValue,
        {"valor_orc2025"}
    ),
    
    // 10. Padronizar texto
    #"Texto em Mai√∫scula" = Table.TransformColumns(
        #"Valor Substitu√≠do2",
        {{"TIPO", Text.Upper, type text}}
    ),
    
    // 11. Limpar caracteres especiais
    #"Valor Substitu√≠do4" = Table.ReplaceValue(
        #"Texto em Mai√∫scula",
        "√î",
        "O",
        Replacer.ReplaceText,
        {"TIPO"}
    ),
    
    // 12. Limpeza final
    #"Texto Limpo" = Table.TransformColumns(
        #"Valor Substitu√≠do4",
        {{"TIPO", Text.Clean, type text}}
    )
in
    #"Texto Limpo"
```

**Perguntas:**
1. Qual a estrutura inicial vs final dos dados?
2. Por que unpivot ‚Üí split ‚Üí pivot (ida e volta)?
3. Quais s√£o as 3 fases principais do pipeline?
4. Por que tantos steps de substitui√ß√£o de valores?

<details>
<summary>üìù Ver Solu√ß√£o</summary>

**Respostas:**

**1. Estrutura Inicial vs Final:**

INICIAL (wide):
```
tipo      | orc_jan_2025 | real_jan_2025 | orc_fev_2025 | real_fev_2025
INSUMOS   | 1000         | 950           | 1100         | 1050
```

FINAL (semi-wide):
```
TIPO      | M√™s | valor_orc2025 | valor_real2025
INSUMOS   | jan | 1000          | 950
INSUMOS   | fev | 1100          | 1050
```

**2. Por que Unpivot ‚Üí Split ‚Üí Pivot?**

- **Unpivot**: Traz todas as colunas mensais para linhas (facilita split)
- **Split**: Separa "orc_jan_2025" em ["orc", "jan", "2025"]
- **Pivot**: Volta "orc" e "real" para colunas (formato final desejado)

√â mais f√°cil processar texto quando est√° em linhas!

**3. Tr√™s Fases Principais:**

**FASE 1 - Reestrutura√ß√£o (steps 1-6):**
- Unpivot ‚Üí Split ‚Üí Pivot
- Objetivo: Formato long com colunas orc/real separadas

**FASE 2 - Limpeza de Dados (steps 7-9):**
- Substituir valores espec√≠ficos
- Converter zeros em null
- Objetivo: Dados limpos e corretos

**FASE 3 - Padroniza√ß√£o de Texto (steps 10-12):**
- Mai√∫sculas
- Remover acentos
- Limpar caracteres especiais
- Objetivo: Texto consistente para an√°lise

**4. Por que Tantas Substitui√ß√µes?**

- **Valor espec√≠fico (5161.73 ‚Üí 0)**: Valor incorreto conhecido no source
- **Zeros ‚Üí null**: Distinguir "sem dados" de "valor zero real"
- **Caracteres especiais**: Garantir compatibilidade e padroniza√ß√£o

**Pipeline Visual:**
```
1. CONECTAR    ‚Üí Redshift (raw)
2. NAVEGAR     ‚Üí dbt_marts.fat_orcamento
3. UNPIVOT     ‚Üí Meses em linhas
4. SPLIT       ‚Üí "orc_jan_2025" ‚Üí ["orc","jan","2025"]
5. LIMPAR      ‚Üí Remove coluna ano
6. PIVOT       ‚Üí orc/real voltam para colunas
7. CORRIGIR    ‚Üí Valores errados
8. PADRONIZAR  ‚Üí Texto limpo e mai√∫sculo
9. ENTREGAR    ‚Üí Tabela final
```

**Conceitos aplicados:**
- Pipeline ETL completo
- Transforma√ß√µes encadeadas
- L√≥gica de reestrutura√ß√£o (unpivot-pivot)
- Qualidade de dados (limpeza + padroniza√ß√£o)
- Navega√ß√£o em objetos aninhados

</details>

---

## Contato

**Jo√£o Lima**  
Contabilidade  
S√≠tio Nossa Senhora Aparecida, Zona Rural  
CEP 14160-970 - Caixa Postal 167  
Sert√£ozinho - S√£o Paulo - Brasil  
Fone: (16) 2105-5300<br>
GitHub: [joaofdl9](https://github.com/joaofdl9)

---

*Documento gerado como parte do processo de handover - Janeiro 2026*
